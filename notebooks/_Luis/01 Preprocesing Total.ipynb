{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6c107bb-1281-42a8-a54d-de27f86ba73d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "from EDA.ValidationData import Validation_data, DataTypeAnalysis\n",
    "from EDA.StatisticalAnalysis import StatisticalAnalysis\n",
    "from EDA.PlotGeometryAnalysis import PlotGeometryAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f60c9cc5-0066-4f3b-8724-a3742dfd33dd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Preprocesing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06654f33-4d4c-4363-8e74-8558a54026bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#1. Leemos los datos de PROCEESED la tabla Delta\n",
    "df_delta2 = spark.read.format(\"delta\").load(\"/mnt/datalakemlopsd4m/presentation/proyectocongestion_presentation/data_congestion_serietemp_balanceada\")\n",
    "datos = df_delta2.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6521f3c5-f4bf-4a44-9f6b-3fb1e011200d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "c_tarjet = ['congestion']\n",
    "c_identidad = ['id_equipment', 'id_equipo', 'id_equipment_congestion', 'id_worker', 'id_trabaj_t', 'id_path', 'tramosidsnew_t']\n",
    "c_categoria = ['n_sat', 'isload_t', 'marcha_t', 'alert_level', 'SERV_BRK_STAT']\n",
    "c_coord = ['precisiongps_t', 'x', 'y', 'z', 'start_xcoorint', 'start_ycoorint', 'start_zcoorint', 'end_xcoorint', 'end_ycoorint', 'end_zcoorint', 'latitude_t', 'longitud_t', 'Lon_Coor', 'Lat_Coor', 'Z_Coor', 'Lat']\n",
    "\n",
    "c_truck_llanta = ['tempeje1_t', 'tempeje2_t', 'tempeje3_t', 'tempeje4_t']\n",
    "c_truck_mov = ['direccion_t', 'speed_t', 'pitch_t', 'roll_t', 'segment_angle_t']\n",
    "c_truck_status = ['tonelaje_t', 'fuel_rate_t', 'combustibleint_t']\n",
    "\n",
    "c_others2 = ['ENG_SPD', 'ENG_OIL_PRES',\n",
    "       'ENG_COOL_TEMP', 'DIFF_LUBE_PRES',\n",
    "       'DIFF_TEMP', 'AUTO_LUBE', 'GROUND_SPD', 'BOOST_PRES',\n",
    "       'THROTTL_POS', 'AMB_AIR_TEMP', 'AIR_FLTR', 'RT_LT_EXH_TEMP',\n",
    "       'LCKUP_SLIP', 'TRN_LUBE_TEMP', 'TRN_OUT_SPD', 'TC_OUT_TEMP', 'RETARDER', 'RETARDER_MODE',\n",
    "       'BRK/AIR_PRES',\n",
    "       'RTF_LTF_BRKTEMP', 'RTR_LTR_BRKTEMP', 'RT_F_BRK_TEMP',\n",
    "       'RT_R_BRK_TEMP', 'LT_R_BRK_TEMP', 'PAYLOAD',\n",
    "       'Tire_Press_N4', 'Tire_Press_N6', 'Hourmeter_MSPU', 'Speed_GPS',\n",
    "       'Direction']\n",
    "\n",
    "c_variables = ['id_equipo', 'id_worker', 'id_path', 'n_sat', 'isload_t', 'marcha_t', 'precisiongps_t', 'x', 'y', 'z', 'direccion_t', 'speed_t', 'pitch_t', 'roll_t', 'segment_angle_t', 'tonelaje_t', 'fuel_rate_t', 'combustibleint_t', 'LCKUP_SLIP', 'BRK/AIR_PRES', 'RTF_LTF_BRKTEMP', 'RTR_LTR_BRKTEMP', 'RT_F_BRK_TEMP', 'RT_R_BRK_TEMP', 'LT_R_BRK_TEMP', 'SERV_BRK_STAT', 'Tire_Press_N4', 'Tire_Press_N6', 'Hourmeter_MSPU', 'Direction']\n",
    "\n",
    "## Columnas eliminar\n",
    "## Sin presencia de registros C4M\n",
    "c_drop1 = ['tempeje5_t', 'tempeje6_t', 'presllanta1_t',\n",
    "       'presllanta2_t', 'presllanta3_t', 'presllanta4_t', 'presllanta5_t',\n",
    "       'presllanta6_t', 'templlanta1_t',\n",
    "       'templlanta2_t', 'templlanta3_t', 'templlanta4_t', 'templlanta5_t',\n",
    "       'templlanta6_t', 'bateriasensorllanta1_t',\n",
    "       'bateriasensorllanta2_t', 'bateriasensorllanta3_t',\n",
    "       'bateriasensorllanta4_t', 'bateriasensorllanta5_t',\n",
    "       'bateriasensorllanta6_t']\n",
    "## Sin presencia de registros H4M\n",
    "c_drop2 = ['SYS_VOLTAGE', 'HI_BOOST_PRES', 'LO_BOOST_PRES', 'BRK_STROKE']\n",
    "\n",
    "## Columnas duplicadas\n",
    "c_drop3 = ['eq_id', 'bearing_t', 'gear_t', 'Gear', 'frecuencia_t']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ddeb8c2-cc32-4823-8deb-a372424fa03d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Filtramos datos atipicos\n",
    "# 1.1. Coordenadas (0,0,0)\n",
    "mask = (datos['x'] == 0) & (datos['y'] == 0) & (datos['z'] == 0)\n",
    "datos = datos[~mask]\n",
    "\n",
    "# 1.2. Filtramos equipos con mayor informacion\n",
    "mask = (datos['eq_id'] == 61) | ((datos['eq_id'] == 199))\n",
    "datos = datos[mask]\n",
    "\n",
    "# 1.3. Filtramos datos con error de satelites\n",
    "mask = (datos['n_sat'] > 0)\n",
    "datos = datos[mask]\n",
    "\n",
    "# 1.4. Filtramos rango de combustible\n",
    "mask = (datos['combustibleint_t'] <= 100) & (datos['combustibleint_t'] >= 0)\n",
    "datos = datos[mask]\n",
    "\n",
    "# 1.5. Filtramos el porcentaje de combustible\n",
    "mask = (datos['Hourmeter_MSPU'] <= 360)\n",
    "datos = datos[mask]\n",
    "\n",
    "# 1.6. Filtramos la temperatura diferencial del vehiculo\n",
    "mask = (datos['DIFF_TEMP'] >= -100)\n",
    "datos = datos[mask]\n",
    "\n",
    "# 1.7. Filtramos porcentaje de lubricante\n",
    "mask = (datos['AUTO_LUBE'] <= 1) & (datos['AUTO_LUBE'] >= 0)\n",
    "datos = datos[mask]\n",
    "\n",
    "# 1.8. Filtramos la temperatura del aire filtrado\n",
    "mask = (datos['RT_LT_EXH_TEMP'] >= -100)\n",
    "datos = datos[mask]\n",
    "\n",
    "# 1.9. Filtramos la presion del lubricante del diferencial del vehiculo\n",
    "mask = (datos['DIFF_LUBE_PRES'] >= -100)\n",
    "datos = datos[mask]\n",
    "\n",
    "# 1.10. Filtramos la temperatura del lubricante de la transmision\n",
    "mask = (datos['TRN_LUBE_TEMP'] <= 101)\n",
    "datos = datos[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "782310b8-a577-4bfc-bd16-bed406a9a748",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. Eliminar columnas\n",
    "# 2.1. Eliminar columnas del C4M y H4M\n",
    "datos = datos.drop(columns=c_drop1+c_drop2+c_drop3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17e0d601-d67b-4e6e-a1e4-75ce9968db32",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d89f2e03-941f-4c2b-bc2f-53e930d9c99d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for categoria in c_categoria:\n",
    "    print(f'----- {categoria} --------')\n",
    "    print(datos[categoria].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d387fa2f-f61a-4ece-aa35-fd50804c8d76",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mes = 3\n",
    "dia = 27\n",
    "mask = (datos['mes'] == mes) & (datos['dia'] == dia)\n",
    "datos[mask][c_categoria].groupby(by=['id_equipment', 'id_worker']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ea3bf82-75fc-4718-b295-3cbd6a20673d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Analisis tramos del camion\n",
    "mes = 3\n",
    "dia = 29\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,5))\n",
    "mask = (datos['mes'] == mes) & (datos['dia'] == dia) #& (datos['id_equipment'] == 198.0)\n",
    "sns.scatterplot(data=datos[mask], x='x', y='y', hue='id_equipment', palette='Dark2', ax=ax[0])\n",
    "mask = (datos['mes'] == mes) & (datos['dia'] == dia) #& (datos['id_equipment'] == 199.0)\n",
    "sns.scatterplot(data=datos[mask], x='x', y='y', hue='id_equipment', palette='Dark2', ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "145f5236-cdab-444a-a637-46d0ba48bbc0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Analisis tramos del camion\n",
    "mes = 3\n",
    "dia = 29\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,5))\n",
    "mask = (datos['mes'] == mes) & (datos['dia'] == dia) #& (datos['id_equipment'] == 198.0)\n",
    "sns.scatterplot(data=datos[mask], x='x', y='y', hue='id_equipo', palette='Dark2', ax=ax[0])\n",
    "mask = (datos['mes'] == mes) & (datos['dia'] == dia) #& (datos['id_equipment'] == 199.0)\n",
    "sns.scatterplot(data=datos[mask], x='x', y='y', hue='id_equipo', palette='Dark2', ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fed795db-f6e7-4477-a884-ec79afe5000c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mask = (datos['mes'] == mes) & (datos['dia'] == dia) & (datos['id_equipment'] == 204.0)\n",
    "data_mes_dia_equip = datos[mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8684c07-0a4b-4819-bada-cb403caa1505",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_mes_dia_equip = data_mes_dia_equip.set_index('instant_date_t')\n",
    "data_mes_dia_equip = data_mes_dia_equip.sort_index()\n",
    "df_time_diffs = data_mes_dia_equip.index.to_series().diff().dt.total_seconds()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7e3cb09-db0b-4156-b4eb-d7a7b7506e0c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_mes_dia_equip[df_time_diffs>2].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1f3a4cd-c237-4c74-865e-c63ce697faae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "set(df_time_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc395f44-8410-4111-bf6b-d27c4a757bd2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "timeanalisis = pd.Timestamp('2024-03-27 10:18:26')\n",
    "timedelta = pd.Timedelta(seconds=173)\n",
    "mask = (data_mes_dia_equip.index < timeanalisis + timedelta) & (data_mes_dia_equip.index > timeanalisis - timedelta)\n",
    "data_mes_dia_equip[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cd2bfe3-5425-40a4-863d-99e7c04ffe72",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "timeanalisis_inf = pd.Timestamp('2024-03-27 10:15:34')\n",
    "timeanalisis_sup = pd.Timestamp('2024-03-27 10:18:30')\n",
    "timedelta = pd.Timedelta(seconds=200)\n",
    "mask = (data_mes_dia_equip.index < timeanalisis_sup + timedelta) & (data_mes_dia_equip.index > timeanalisis_inf - timedelta)\n",
    "data_mes_dia_equip[mask]#['x'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80832a70-189a-4a42-a7ae-031d341d6286",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=data_mes_dia_equip[mask], x='x', y='y', hue='id_equipment', palette='Dark2')\n",
    "ax[1].set_title(data_mes_dia_equip[mask].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7c98f88-9fe6-4e5f-bf94-f41613eddf9e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#3. Eliminamos o Filtramos las filas donde la diferencia es distinta de cero (Con ello eliminamos las filas o registros de fechas duplicadas)\n",
    "data_mes_dia_equip = data_mes_dia_equip[df_time_diffs != 0]\n",
    "\n",
    "#4. # Reinterpolar el dataset con una periosidad en especifico\n",
    "# 'S' o 'seg' : Segundo, 'T' o 'min': Minuto,'H' o 'Hr': Hora,'D': Día,'W': Semana,'M': Mes,'Q': Trimestre,'Y': Año\n",
    "data_mes_dia_equip = data_mes_dia_equip.asfreq(freq='6S', method='bfill')\n",
    "\n",
    "data_mes_dia_equip = data_mes_dia_equip.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8b6fec6-9270-4ec3-b402-03b4783f8583",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Analisis tramos del camion\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,5))\n",
    "mask = (datos['mes'] == mes) & (datos['dia'] == dia) & (datos['id_equipment'] == 204.0)\n",
    "sns.scatterplot(data=datos[mask], x='x', y='y', hue='id_equipment', palette='Dark2', ax=ax[0])\n",
    "ax[0].set_title(datos[mask].shape)\n",
    "sns.scatterplot(data=data_mes_dia_equip, x='x', y='y', hue='id_equipment', palette='Dark2', ax=ax[1])\n",
    "ax[1].set_title(data_mes_dia_equip.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fe8ebfc-d1b8-4287-87b7-f233813db044",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos[mask]#.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "133b5955-368d-4a37-804f-a5ab0847d546",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_mes_dia_equip#.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1e861bf-b4f6-4bd1-ad2b-5a50d86751aa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Hacer el Balanceo de datos import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    " \n",
    "# Convertimos a index la fecha\n",
    "datos = datos.set_index('instant_date_t')\n",
    "\n",
    "# Eliminamos registros con coordenadas (0,0,0)\n",
    "mask = (datos['x']>0) & (datos['y']>0) & (datos['z']>0)\n",
    "datos = datos[mask]\n",
    "\n",
    "# Eliminacion de variables tipo object\n",
    "datos = datos.drop(columns=['nombre', 'nombre_equipo'])\n",
    "\n",
    "\n",
    "# Filtrar las fechas donde congestion == 1\n",
    "fechas_congestion_1 = datos[datos['congestion'] == 1].index\n",
    " \n",
    "# Generar un rango de fechas completo dentro del rango del DataFrame\n",
    "fecha_min = datos.index.min()\n",
    "fecha_max = datos.index.max()\n",
    "rango_completo = pd.date_range(start=fecha_min, end=fecha_max, freq='S')\n",
    " \n",
    "# Excluir las fechas de congestion == 1 del rango completo\n",
    "fechas_disponibles = rango_completo.difference(fechas_congestion_1)\n",
    " \n",
    "# Aplicar SMOTE para generar nuevas muestras de la clase minoritaria (congestion == 0)\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    " \n",
    "# Usar todas las columnas como características para SMOTE excepto 'congestion'\n",
    "X = datos.drop(columns=['congestion'])\n",
    "y = datos['congestion']\n",
    " \n",
    "# Convertir las fechas del índice a números para usarlas con SMOTE\n",
    "X['instant_date_num'] = X.index.astype(int) / 10**9  # Convertir a segundos\n",
    " \n",
    "# Aplicar SMOTE\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    " \n",
    "# Convertir de nuevo a DataFrame\n",
    "X_res = pd.DataFrame(X_res, columns=X.columns)\n",
    "y_res = pd.Series(y_res, name='congestion')\n",
    " \n",
    "# Filtrar las nuevas muestras generadas por SMOTE (la diferencia entre las originales y las nuevas)\n",
    "nuevas_muestras = X_res[len(datos):]\n",
    "nuevas_congestion = y_res[len(datos):]\n",
    " \n",
    "# Asignar nuevas fechas secuenciales de fechas_disponibles a las nuevas muestras\n",
    "nuevas_fechas_asignadas = fechas_disponibles[:len(nuevas_muestras)]\n",
    "nuevas_muestras['instant_date'] = nuevas_fechas_asignadas\n",
    " \n",
    "# Crear el DataFrame final combinando los datos originales y las nuevas muestras\n",
    "nuevas_muestras = nuevas_muestras.set_index('instant_date')\n",
    "nuevas_muestras = nuevas_muestras.drop(columns=['instant_date_num'])\n",
    "nuevas_muestras['congestion'] = nuevas_congestion.values\n",
    " \n",
    "# Combinar los datos originales y las nuevas muestras\n",
    "datos_cong_balanceado = pd.concat([datos, nuevas_muestras]).sort_index()\n",
    "\n",
    "datos_cong_balanceado.index.name = 'instant_date_t'\n",
    "#datos_cong_balanceado = datos_cong_balanceado.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3cff42e-d1ef-40d1-a6dd-efea23504d3a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mask = (datos_cong_balanceado['x'] == 0) & (datos_cong_balanceado['y'] == 0) & (datos_cong_balanceado['z'] == 0)\n",
    "datos_cong_balanceado[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87902be7-3565-4b25-b939-da6584133058",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. Convertir el DataFrame de Pandas a un DataFrame de Spark\n",
    "spark_datos = spark.createDataFrame(datos_cong_balanceado)\n",
    " \n",
    "# 4. Guardar los datos preprocesados en una tabla Delta en el Azure Storage\n",
    "# Asegurar que las columnas de fecha y hora mantengan sus tipos de datos\n",
    "#spark_datos = spark_datos.withColumn(\"Event_Date\", col(\"Event_Date\").cast(\"timestamp\"))\n",
    "#spark_datos = spark_datos.withColumn(\"instant_date_t\", col(\"instant_date_t\").cast(\"timestamp\"))\n",
    " \n",
    "# Nombre de la tabla Delta a guardar\n",
    "nombre_tabla_delta = \"dbproyectocongestion_presentation.tablacaracteristicas_congestion_tabladelta_2\"\n",
    " \n",
    "# 4.1 Verificar si ya existe la tabla Delta\n",
    "if spark.catalog.tableExists(nombre_tabla_delta):\n",
    "    # Eliminar la tabla Delta existente\n",
    "    spark.sql(\"DROP TABLE IF EXISTS \" + nombre_tabla_delta)\n",
    " \n",
    "# 4.2 Guardar los datos preprocesados en una tabla Delta\n",
    "spark_datos.write.format(\"delta\").mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(nombre_tabla_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d5bb1b6-0828-4b69-91e0-10798783d10f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "015ab866-4223-4323-b73b-58a0fdfc87d0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1761a709-1579-4b62-a6fe-6aedb45173d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ad31f6c-1767-458f-96e3-b2a5ccbb5dde",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Leer Datos Sin Balancear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07b83c4b-68fa-4e47-9835-bf85093e6531",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from EDA.ValidationData import Validation_data, DataTypeAnalysis\n",
    "from EDA.StatisticalAnalysis import StatisticalAnalysis\n",
    "from EDA.PlotGeometryAnalysis import PlotGeometryAnalysis\n",
    "\n",
    "#1. Leemos los datos de PROCEESED la tabla Delta\n",
    "# /mnt/datalakemlopsd4m/processed/proyectocongestion_processed/datapreprocessed_congestion_tabladelta\n",
    "df_delta = spark.read.format(\"delta\").load(\"/mnt/datalakemlopsd4m/presentation/proyectocongestion_presentation/data_congestion_serietemp_balanceada\")\n",
    "datos_sin_balanceo = df_delta.toPandas()\n",
    "\n",
    "# 2. Limpieza de variables No prioritarias\n",
    "columnas_a_eliminar = ['nombre_equipo','nombre', 'nombre_equipo','nombre','start_time_alert','end_time_alert','Event_Date']\n",
    "\n",
    "# 2.1 Filtrar las columnas que existen en el DataFrame\n",
    "columnas_existentes = [col for col in columnas_a_eliminar if col in datos_sin_balanceo.columns]\n",
    "\n",
    "# 2.2 Verificar si hay columnas para eliminar\n",
    "if columnas_existentes:\n",
    "    datos_sin_balanceo.drop(columnas_existentes, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Filtramos los valores de x, y, z que son 0s\n",
    "mask = (datos_sin_balanceo['x'] == 0) & (datos_sin_balanceo['y'] == 0) & (datos_sin_balanceo['z'] == 0)\n",
    "datos_sin_balanceo = datos_sin_balanceo[~mask]\n",
    "\n",
    "# 3.2. Filtramos equipos con mayor informacion\n",
    "mask = (datos_sin_balanceo['id_equipo'] == 61) | ((datos_sin_balanceo['id_equipo'] == 199))\n",
    "datos_sin_balanceo = datos_sin_balanceo[mask]\n",
    "\n",
    "# 3.3. Filtramos datos con error de satelites\n",
    "mask = (datos_sin_balanceo['n_sat'] > 0)\n",
    "datos_sin_balanceo = datos_sin_balanceo[mask]\n",
    "\n",
    "# 3.4. Filtramos rango de combustible\n",
    "mask = (datos_sin_balanceo['combustibleint_t'] <= 100) & (datos_sin_balanceo['combustibleint_t'] >= 0)\n",
    "datos_sin_balanceo = datos_sin_balanceo[mask]\n",
    "\n",
    "# 3.5. Filtramos el porcentaje de combustible\n",
    "mask = (datos_sin_balanceo['Hourmeter_MSPU'] <= 360)\n",
    "datos_sin_balanceo = datos_sin_balanceo[mask]\n",
    "\n",
    "# 3.6. Filtramos la temperatura diferencial del vehiculo\n",
    "mask = (datos_sin_balanceo['DIFF_TEMP'] >= -100)\n",
    "datos_sin_balanceo = datos_sin_balanceo[mask]\n",
    "\n",
    "# 3.7. Filtramos porcentaje de lubricante\n",
    "mask = (datos_sin_balanceo['AUTO_LUBE'] <= 1) & (datos_sin_balanceo['AUTO_LUBE'] >= 0)\n",
    "datos_sin_balanceo = datos_sin_balanceo[mask]\n",
    "\n",
    "# 3.8. Filtramos la temperatura del aire filtrado\n",
    "mask = (datos_sin_balanceo['RT_LT_EXH_TEMP'] >= -100)\n",
    "datos_sin_balanceo = datos_sin_balanceo[mask]\n",
    "\n",
    "# 3.9. Filtramos la presion del lubricante del diferencial del vehiculo\n",
    "mask = (datos_sin_balanceo['DIFF_LUBE_PRES'] >= -100)\n",
    "datos_sin_balanceo = datos_sin_balanceo[mask]\n",
    "\n",
    "# 3.10. Filtramos la temperatura del lubricante de la transmision\n",
    "mask = (datos_sin_balanceo['TRN_LUBE_TEMP'] <= 101)\n",
    "datos_sin_balanceo = datos_sin_balanceo[mask]\n",
    "\n",
    "\n",
    "datos = datos_sin_balanceo.copy()\n",
    "\n",
    "\n",
    "# Convertimos a index la fecha\n",
    "datos = datos.set_index('instant_date_t')\n",
    "\n",
    "datos = datos.sort_index()\n",
    "\n",
    "#2.4 Identificamos la periocidad de la serie temporal\n",
    "df_time_diffs = datos.index.to_series().diff().dt.total_seconds()\n",
    " \n",
    "# # 2.4.1 Contar cuántas diferencias de tiempo tienen cada valor específico\n",
    "# diferencias_frecuencias = df_time_diffs.value_counts().sort_index()\n",
    "# # 2.4.2 Mostrar los recuentos\n",
    "# print(diferencias_frecuencias)\n",
    " \n",
    "#3. Eliminamos o Filtramos las filas donde la diferencia es distinta de cero (Con ello eliminamos las filas o registros de fechas duplicadas)\n",
    "datos = datos[df_time_diffs != 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0805ce02-3fbe-4981-a9f2-ab8c1071e338",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#4. # Reinterpolar el dataset con una periosidad en especifico\n",
    "# 'S' o 'seg' : Segundo, 'T' o 'min': Minuto,'H' o 'Hr': Hora,'D': Día,'W': Semana,'M': Mes,'Q': Trimestre,'Y': Año\n",
    "datos = datos.asfreq(freq='6S', method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af02bc9d-bd4c-4774-b4f8-a54312312573",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f25a4ba-21d5-4225-aee9-bd6576ffc95f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Filtrar las fechas donde congestion == 1\n",
    "fechas_congestion_1 = datos[datos['congestion'] == 1].index\n",
    "\n",
    "# Generar un rango de fechas completo dentro del rango del DataFrame\n",
    "fecha_min = datos.index.min()\n",
    "fecha_max = datos.index.max()\n",
    "rango_completo = pd.date_range(start=fecha_min, end=fecha_max, freq='S')\n",
    "\n",
    "# Excluir las fechas de congestion == 1 del rango completo\n",
    "fechas_disponibles = rango_completo.difference(fechas_congestion_1)\n",
    "\n",
    "# Aplicar SMOTE para generar nuevas muestras de la clase minoritaria (congestion == 0)\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# Usar todas las columnas como características para SMOTE excepto 'congestion'\n",
    "X = datos.drop(columns=['congestion'])\n",
    "y = datos['congestion']\n",
    "\n",
    "# Convertir las fechas del índice a números para usarlas con SMOTE\n",
    "X['instant_date_num'] = X.index.astype(int) / 10**9  # Convertir a segundos\n",
    "\n",
    "# Aplicar SMOTE\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "# Convertir de nuevo a DataFrame\n",
    "X_res = pd.DataFrame(X_res, columns=X.columns)\n",
    "y_res = pd.Series(y_res, name='congestion')\n",
    "\n",
    "# Filtrar las nuevas muestras generadas por SMOTE (la diferencia entre las originales y las nuevas)\n",
    "nuevas_muestras = X_res[len(datos):]\n",
    "nuevas_congestion = y_res[len(datos):]\n",
    "\n",
    "# Asignar nuevas fechas secuenciales de fechas_disponibles a las nuevas muestras\n",
    "nuevas_fechas_asignadas = fechas_disponibles[:len(nuevas_muestras)]\n",
    "nuevas_muestras['instant_date'] = nuevas_fechas_asignadas\n",
    "\n",
    "# Crear el DataFrame final combinando los datos originales y las nuevas muestras\n",
    "nuevas_muestras = nuevas_muestras.set_index('instant_date')\n",
    "nuevas_muestras = nuevas_muestras.drop(columns=['instant_date_num'])\n",
    "nuevas_muestras['congestion'] = nuevas_congestion.values\n",
    "\n",
    "# Combinar los datos originales y las nuevas muestras\n",
    "datos_balanceados = pd.concat([datos, nuevas_muestras]).sort_index()\n",
    "\n",
    "\n",
    "datos_balanceados = datos_balanceados.reset_index(names='instant_date_t')\n",
    "\n",
    "# 3. Convertir el DataFrame de Pandas a un DataFrame de Spark\n",
    "spark_datos = spark.createDataFrame(datos_balanceados)\n",
    " \n",
    "# 4. Guardar los datos preprocesados en una tabla Delta en el Azure Storage\n",
    "# Asegurar que las columnas de fecha y hora mantengan sus tipos de datos\n",
    "#spark_datos = spark_datos.withColumn(\"Event_Date\", col(\"Event_Date\").cast(\"timestamp\"))\n",
    "#spark_datos = spark_datos.withColumn(\"instant_date_t\", col(\"instant_date_t\").cast(\"timestamp\"))\n",
    " \n",
    "# Nombre de la tabla Delta a guardar\n",
    "nombre_tabla_delta = \"dbproyectocongestion_presentation.tablacaracteristicas_congestion_tabladelta_v3\"\n",
    " \n",
    "# 4.1 Verificar si ya existe la tabla Delta\n",
    "if spark.catalog.tableExists(nombre_tabla_delta):\n",
    "    # Eliminar la tabla Delta existente\n",
    "    spark.sql(\"DROP TABLE IF EXISTS \" + nombre_tabla_delta)\n",
    " \n",
    "# 4.2 Guardar los datos preprocesados en una tabla Delta\n",
    "spark_datos.write.format(\"delta\").mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(nombre_tabla_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28bdc106-9b4f-4052-a1e7-c25b43fb65ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_balanceados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd65370d-d4fb-45de-be28-3cc78df0374e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#1. Leemos los datos de PROCEESED la tabla Delta\n",
    "df_delta2 = spark.read.format(\"delta\").load(\"/mnt/datalakemlopsd4m/presentation/proyectocongestion_presentation/tablacaracteristicas_congestion_tabladelta_v3\")\n",
    "datos = df_delta2.toPandas()\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab71ffb6-06de-4cbf-9e87-8b1d2b8a4a71",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24e33995-7c48-4b1f-afad-ab3b95b31a74",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos['congestion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a40c4b51-7df3-40bb-ba4a-8175f12f27d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos['n_sat'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18283315-87c0-490c-81b5-212a17ffe2d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convertimos a index la fecha\n",
    "datos = datos.set_index('instant_date_t')\n",
    "#2.4 Identificamos la periocidad de la serie temporal\n",
    "df_time_diffs = datos.index.to_series().diff().dt.total_seconds()\n",
    " \n",
    "# # 2.4.1 Contar cuántas diferencias de tiempo tienen cada valor específico\n",
    "diferencias_frecuencias = df_time_diffs.value_counts().sort_index()\n",
    "# # 2.4.2 Mostrar los recuentos\n",
    "print(diferencias_frecuencias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc519bdb-d89c-485b-ab9c-6c61d6b4b10c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos['x'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a96b7e8-7a13-4fc2-b2f3-22be75249007",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# #2. Ajuste de los datos a Series Temporales\n",
    "# # #2.1 Se establece la columna 'Time' como el índice del DataFrame \"datos\"\n",
    "# datos = datos.set_index('instant_date_t')\n",
    "\n",
    "# #2.3 Ordenamos el dataset de forma ascendente segun el datetime\n",
    "datos.sort_index(inplace=True)\n",
    "\n",
    "#2.4 Identificamos la periocidad de la serie temporal\n",
    "df_time_diffs = datos.index.to_series().diff().dt.total_seconds()\n",
    "\n",
    "# # 2.4.1 Contar cuántas diferencias de tiempo tienen cada valor específico\n",
    "# diferencias_frecuencias = df_time_diffs.value_counts().sort_index()\n",
    "# # 2.4.2 Mostrar los recuentos\n",
    "# print(diferencias_frecuencias)\n",
    "\n",
    "#3. Eliminamos o Filtramos las filas donde la diferencia es distinta de cero (Con ello eliminamos las filas o registros de fechas duplicadas)\n",
    "datos = datos[df_time_diffs != 0]\n",
    "\n",
    "#4. # Reinterpolar el dataset con una periosidad en especifico\n",
    "# 'S' o 'seg' : Segundo, 'T' o 'min': Minuto,'H' o 'Hr': Hora,'D': Día,'W': Semana,'M': Mes,'Q': Trimestre,'Y': Año\n",
    "#datos_cong_balanceado = datos_cong_balanceado.asfreq(freq='5T', method='bfill')\n",
    "datos = datos.asfreq(freq='6s', method='bfill')\n",
    "\n",
    "# Filtramos los valores de x, y, z que son 0s\n",
    "mask = (datos['x'] == 0) & (datos['y'] == 0) & (datos['z'] == 0)\n",
    "datos = datos[~mask]\n",
    "\n",
    "datos.head()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01 Preprocesing Total",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
