{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b466958e-22fd-4698-b677-b0ebb1f68426",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Librerias que se usaran\n",
    "import pandas as pd  # Libreria para administrar tablas, y realizar trabajos con distintas formas de tablas o dataframes\n",
    "import numpy as np   # Libreria para poder hacer operaciones matematicas y matriciales\n",
    "import matplotlib.pyplot as plt # Libreria para realizar graficos \n",
    "from tabulate import tabulate   # Permite formatear y mostrar de mejor manera los datos tabulares\n",
    "import seaborn as sns  # Libreria para realizar graficos y vizualizaciones\n",
    "import psycopg2        # Libreria que permite la conexion con PostgresSQL\n",
    "from matplotlib.backends.backend_pdf import PdfPages # Libreria que permite exportar graficos en pdf\n",
    "\n",
    "#Configuramos pandas para que podamos vizualizar todas las columnas y filas la estadistica descriptiva de todas las variables\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "#Configuramos pandas para que lanze valores con una precision de hasta 6 decimales\n",
    "pd.set_option('display.float_format', '{:.6f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80354573-4321-4c13-b594-746abd89d8a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Informaci贸n de la conexi贸n a PostgreSQL\n",
    "host = \"srv-postgres-d4m.postgres.database.azure.com\"\n",
    "database = \"ControlSenseDB\"\n",
    "user = \"administrador\"\n",
    "password = \"Protobuffers2024\"\n",
    "\n",
    "# Establecer la conexi贸n a la base de datos\n",
    "try:\n",
    "    connection = psycopg2.connect(\n",
    "        host=host,\n",
    "        database=database,\n",
    "        user=user,\n",
    "        password=password\n",
    "    )\n",
    "\n",
    "    # Crear un cursor para ejecutar comandos SQL\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Establecer la zona horaria antes de ejecutar la consulta\n",
    "    time_zone_query = \"SET TIME ZONE 'America/Lima';\"\n",
    "    cursor.execute(time_zone_query)\n",
    "\n",
    "    # Tu consulta SQL equipos de acarreo a considerar en c4mequipos y datacamion: 61,63,64,65,68,69,71,74,103,122,125,126,198,199,201,204,205\n",
    "    # equipos acarreo disponibles en telemetria h4m(2dias) : 61,65,68,126,199,201,*204*,205\n",
    "    tu_query_sql = '''\n",
    "    SELECT *\n",
    "    FROM public.getsensorsvaluesmod(205, '2024-02-27 07:00:30.612-05', '2024-03-03 06:27:30.612-05') a --data_camion\n",
    "    left join tp_tramosstat b\n",
    "    on b.id = (select id from tp_tramosstat where id_tptramosstat = a.tramosidsnew_t and tiem_creac < a.instant_date_t\n",
    "                    order by tiem_creac desc limit 1)\n",
    "    where b.nombre_tramo is not null\n",
    "    order by a.instant_date_t asc\n",
    "    '''\n",
    "    # Ejecutar la consulta\n",
    "    cursor.execute(tu_query_sql)\n",
    "\n",
    "    # Obtener los resultados en un DataFrame de pandas\n",
    "    resultados14 = pd.DataFrame(cursor.fetchall(), columns=[desc[0] for desc in cursor.description])\n",
    "\n",
    "    # Cerrar el cursor y la conexi贸n\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "\n",
    "    # Hacer lo que necesites con los resultados\n",
    "    print(resultados14.head())\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error al conectar a la base de datos PostgreSQL:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8dab1b61-2df8-4365-a40d-d5b0d817c6e4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Metodo 2: Guardarmos directamente el dfpandas en un csv en el BlobStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1931775-096f-4956-b03f-3700643b48c9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "\n",
    "# Convertir el DataFrame de Pandas a CSV\n",
    "resultados14.to_csv(\"datos_raw_shougang_equipo205.csv\", index=False)\n",
    "\n",
    "# # Obtener la conection, del Azure DataLake, se encuentra en la interfaz de Azure (Claves de acceso: Key1)\n",
    "# conection_string = 'DefaultEndpointsProtocol=https;AccountName=datalakemlopsd4m;AccountKey=iWT8t74/#XlqcqoR03keDVtFZPzr0PB9zDffMPaLWMUBIAjUww8uYAVkc9xRkcBtvTmUHKBvd1sB3+ASt6mGgcQ==;EndpointSuffix=core.windows.net'\n",
    "\n",
    "# Conectar al Blob Storage de Azure\n",
    "blob_service_client = BlobServiceClient.from_connection_string(conection_string)\n",
    "\n",
    "# Nombre del contenedor y archivo en el Blob Storage\n",
    "container_name = \"raw/proyectocongestion_raw/fuentedatos_c4m/operacion_shougang/\"\n",
    "blob_name = \"datos_raw_shougang_equipo205.csv\"\n",
    "\n",
    "# Subir el archivo CSV al Blob Storage\n",
    "with open(\"datos_raw_shougang_equipo205.csv\", \"rb\") as data:\n",
    "    blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
    "    blob_client.upload_blob(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f336d3d-f0e0-4423-b0e5-831dbbcb1030",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1.ingestion_data",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
