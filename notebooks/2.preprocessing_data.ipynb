{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c2a29b4-8a6b-49e2-90c3-3e4509e93b77",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 1. Cargamos los datos a Preprocesar y limpiar (desde el BlobStorage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "269d6fae-2fe9-41e5-9301-041979bfcc42",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Librerias necesarias para usar el Azure DataLake y DataBrinks\n",
    "import pandas as pd\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "import io\n",
    "\n",
    "# 2. Obtener conection Azure DataLake,interfaz de Azure(Claves de acceso: Key1) (Debes comentar esta variable Si NO deja hacer COMMIT DEL \n",
    "# CODIGO EN GIT,GITHUB)\n",
    "# connection_string = 'DefaultEndpointsProtocol=https;AccountName=datalakemlopsd4m;AccountKey=iWT8t74/#XlqcqoR03keDVtFZPzr0PB9zDffMPaLWMUBIAjUww8uYAVkc9xRkcBtvTmUHKBvd1sB3+ASt6mGgcQ==;EndpointSuffix=core.windows.net'\n",
    "\n",
    "# 3. Conectar al Blob Storage de Azure\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "\n",
    "# 4. Identificamos el nombre del contenedor(container_name) y nombre del archivo(definir blob_name) en el Blob Storage\n",
    "container_name = \"raw/proyectocongestion_raw/fuentedatos_consolidado/\"\n",
    "blob_name = \"datos_raw_consolidado.csv\"\n",
    "\n",
    "# 5. Obtener el blob_client\n",
    "blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
    "\n",
    "# 6. Leer el contenido del blob como texto\n",
    "blob_data = blob_client.download_blob().content_as_text()\n",
    "\n",
    "# 7. Leer el archivo CSV en un DataFrame de Pandas desde el texto\n",
    "datos = pd.read_csv(io.StringIO(blob_data))\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09e8189b-dafd-47e5-9410-ca1072531696",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12bed355-748f-4cf0-871c-57650385a886",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos[\"eq_id\"].unique()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2.preprocessing_data",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
