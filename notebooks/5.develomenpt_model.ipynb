{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b07ea02b-4ec7-41a0-a385-1ac8a25e9534",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Tratamiento de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Graficos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "import plotly.express as px\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['lines.linewidth'] = 1.5\n",
    "%matplotlib inline\n",
    "\n",
    "# Modelado y Forescasting\n",
    "#from lightgbm import LGBMRegressor    #Regressor mas potente de gradient bossting\n",
    "# from skforecast.ForecasterAutoreg import ForecasterAutoreg  # Modelo autoregressivo\n",
    "# from skforecast.model_selection import grid_search_forecaster # Encontrar los mejores hiperparametros(optimizar el modelo)\n",
    "# from skforecast.model_selection import backtesting_forecaster  # Evaluar el modelo si hubiese estado en produccion\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "#Configuration warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de3c27e2-0516-4016-8106-7a6000dce16e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Librerias que se usaran\n",
    "import pandas as pd  # Libreria para administrar tablas, y realizar trabajos con distintas formas de tablas o dataframes\n",
    "import numpy as np   # Libreria para poder hacer operaciones matematicas y matriciales \n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "#1. Leemos los datos de TABLA CARACTERISTICAS la tabla Delta de storage Presentation \n",
    "#df_delta = spark.read.format(\"delta\").load(\"/mnt/datalakemlopsd4m/presentation/proyectocongestion_presentation/#tablacaracteristicas_congestion_tabladelta\")\n",
    "df_delta = spark.read.format(\"delta\").load(\"/mnt/datalakemlopsd4m/processed/proyectocongestion_processed/datapreprocessed_congestion_tabladelta\")\n",
    "\n",
    "datos = df_delta.toPandas()\n",
    "\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54d80ec5-9ab5-4b8a-8996-469157098e73",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Configuramos pandas para que podamos vizualizar todas las columnas y filas la estadistica descriptiva de todas las variables\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "#Configuramos pandas para que lanze valores con una precision de hasta 6 decimales\n",
    "pd.set_option('display.float_format', '{:.6f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "febb9e01-5bd2-47bc-966b-9fcee4382635",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1437943b-19de-412b-a1b7-c405b83bebd2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 1. Ajuste de los datos a Series Temporales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3c69a2a-5d48-467a-954a-4b5454e55490",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#2. Ajuste de los datos a Series Temporales\n",
    "#2.1 Se establece la columna 'Time' como el índice del DataFrame \"datos\"\n",
    "datos = datos.set_index('instant_date_t')\n",
    "\n",
    "#2.3 Ordenamos el dataset de forma ascendente segun el datetime\n",
    "datos.sort_index(inplace=True)\n",
    "\n",
    "#2.4 Identificamos la periocidad de la serie temporal\n",
    "df_time_diffs = datos.index.to_series().diff().dt.total_seconds()\n",
    "\n",
    "#3. Eliminamos o Filtramos las filas donde la diferencia es distinta de cero (Con ello eliminamos las filas o registros de fechas duplicadas)\n",
    "datos = datos[df_time_diffs != 0]\n",
    "\n",
    "#4. # Reinterpolar el dataset con una periosidad en especifico\n",
    "# 'S' o 'seg' : Segundo, 'T' o 'min': Minuto,'H' o 'Hr': Hora,'D': Día,'W': Semana,'M': Mes,'Q': Trimestre,'Y': Año\n",
    "datos = datos.asfreq(freq='T', method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f200046c-455d-4475-bf36-a6c65bcc66d5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb3c5155-e0df-4e36-ad57-9166867548a0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 2. Separacion de los datos en Train-Validation-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3495a2b0-e138-42a2-907e-9cc3850ac937",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Obtener la fecha mínima y máxima del índice\n",
    "fecha_minima = datos.index.min()\n",
    "fecha_maxima = datos.index.max()\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Fecha mínima:\", fecha_minima)\n",
    "print(\"Fecha máxima:\", fecha_maxima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8f66b4e-2279-41c0-b2aa-dbd0cddb7bc7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Separacion de los datos en Train-Validation-Test\n",
    "datos = datos.loc[fecha_minima: fecha_maxima]\n",
    "fin_train = '2024-03-01 18:47:18'\n",
    "fin_validacion = '2024-03-01 21:47:18'\n",
    "datos_train = datos.loc[:fin_train, :] #Un año\n",
    "datos_val = datos.loc[fin_train:fin_validacion, :] #2 meses\n",
    "datos_test = datos.loc[fin_validacion: , :] # 3 meses\n",
    "\n",
    "print(f\"Fechas train: {datos_train.index.min()} ... {datos_train.index.max()} (n={len(datos_train)})\")\n",
    "print(f\"Fechas validacion: {datos_val.index.min()} ... {datos_val.index.max()} (n={len(datos_val)})\")\n",
    "print(f\"Fechas test: {datos_test.index.min()} ... {datos_test.index.max()} (n={len(datos_test)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef28ac61-2581-4b14-a263-aea852def21d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(datos_train.shape,datos_val.shape, datos_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97518463-fd76-4cfc-9e5f-a91543311ee8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 3.Grafico de la serie temporal (train,validation, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a2667ee-6293-4b21-9e4d-25e1902b7d91",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Grafico de la serie temporal\n",
    "\n",
    "#crea una nueva figura y un par de ejes (axes) dentro de la figura\n",
    "fig, ax = plt.subplots(figsize=(15,4)) # figsize=(15,4) establece el tamaño de la figura en 15 unidades de ancho y 4 unidades de alto.\n",
    "\n",
    "#Las series se colorean automáticamente según una paleta de colores predefinida por matplotlib\n",
    "datos_train.speed_t.plot(ax=ax, label=\"entrenamiento\", linewidth=1)\n",
    "datos_val.speed_t.plot(ax=ax, label=\"validacion\", linewidth=1)\n",
    "datos_test.speed_t.plot(ax=ax, label=\"test\", linewidth=1)\n",
    "ax.set_title('speed_t')\n",
    "ax.legend();"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "5.develomenpt_model",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
