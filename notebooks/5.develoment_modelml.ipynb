{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d541d69a-2580-4d9a-841d-651f30bc5dae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Tratamiento de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Graficos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "import plotly.express as px\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "#Configuramos pandas para que lanze valores con una precision de hasta 6 decimales\n",
    "pd.set_option('display.float_format', '{:.6f}'.format)\n",
    "import sys\n",
    "# Establecer la opción de impresión para mostrar el array completo\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b65bed5-03f5-49e4-b6c8-4a5db456dcf6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 1. Modelo de Machine Learning Con Datos Balanceados en Series Temporales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44b4fea6-9347-4fa1-a0b6-3fafec2736e4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    " Leemos los datos de PRESENTATION la tabla Delta con los datos Crudos Sin Balanceo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3cf2a5c-312c-442d-a493-a9d40efd5a34",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#1. Leemos los datos de PROCEESED la tabla Delta \n",
    "df_delta = spark.read.format(\"delta\").load(\"/mnt/datalakemlopsd4m/presentation/proyectocongestion_presentation/tablacaracteristicas_congestion_tabladelta\")\n",
    "datos = df_delta.toPandas()\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32d706f4-1751-4fba-8f8a-03a2235a82f3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#datos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61851550-2f98-48e0-9bf1-b5ec566f993d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos['congestion'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2689d270-ca1d-469d-ad85-9ae6c82cde1f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 2.Eliminar las variables que no ingresaran al Modelo de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "981dd997-e9e3-435c-aecd-901896cae752",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#datos.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54f6bf8d-f837-4f5e-9cdf-b50b8b79854e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. Limpieza de variables No prioritarias\n",
    "columnas_a_eliminar = ['nombre_equipo','nombre','start_time_alert','end_time_alert','Event_Date']\n",
    "\n",
    "# 2.1 Filtrar las columnas que existen en el DataFrame\n",
    "columnas_existentes = [col for col in columnas_a_eliminar if col in datos_sin_balanceo.columns]\n",
    "\n",
    "# 2.2 Verificar si hay columnas para eliminar\n",
    "if columnas_existentes:\n",
    "    datos_sin_balanceo.drop(columnas_existentes, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a488a22f-fdfc-4254-997b-b9c55737c517",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Convertimos a index la fecha\n",
    "datos = datos.set_index('instant_date_t')\n",
    "\n",
    "# Filtrar las fechas donde congestion == 1\n",
    "fechas_congestion_1 = datos[datos['congestion'] == 1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8b22403-b69f-45ba-a328-6cb35dfeb626",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fechas_congestion_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "757125d9-7bed-4ebc-bc13-fa325cad8eeb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Generar un rango de fechas completo dentro del rango del DataFrame\n",
    "fecha_min = datos.index.min()\n",
    "fecha_max = datos.index.max()\n",
    "rango_completo = pd.date_range(start=fecha_min, end=fecha_max, freq='S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25f3f19f-5290-4d90-8088-956918d5a417",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fecha_min, fecha_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29559656-58f9-450b-927e-100e26830b05",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rango_completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "929f358c-8ac1-4ee8-83e0-54ffe68dff5f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Excluir las fechas de congestion == 1 del rango completo\n",
    "fechas_disponibles = rango_completo.difference(fechas_congestion_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c20e1c36-321b-46c3-9b4d-067ee4a7a06d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fechas_disponibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2821d99-cd16-4669-aa65-08f041bd1b09",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Aplicar SMOTE para generar nuevas muestras de la clase minoritaria (congestion == 0)\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42) # la clase minoritaria será sobre-muestreada hasta sea igual al mayoritario\n",
    "X = np.arange(len(datos)).reshape(-1, 1)  # Crear una secuencia numérica, SMOTE espera que X sea una matriz de dos dimensiones\n",
    "y = datos['congestion']  #variable objetivo (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd8ad73f-bae8-429c-ace8-f6814197d133",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Aplicar SMOTE\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "# Convertir las nuevas muestras a DataFrame\n",
    "datos_resampleados = pd.DataFrame({'index': X_res.flatten(), 'congestion': y_res})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b71f49e-29d3-4d9c-9200-0ab50c5de385",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_resampleados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da87f33a-fc5b-4f13-9f4b-88b618441863",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_resampleados['congestion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4fe07b9-dc31-463d-a093-01c7a5500e3a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filtrar las nuevas muestras generadas por SMOTE (la diferencia entre las originales y las nuevas)\n",
    "nuevas_muestras = datos_resampleados[len(datos):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c0db266-b8a9-4ba0-9d11-a70b1ee9a5a6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "nuevas_muestras.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fbeb0d0-f5a6-490c-a372-c1fe4a6dc116",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Asignar nuevas fechas secuenciales de fechas_disponibles a las nuevas muestras\n",
    "nuevas_fechas_asignadas = fechas_disponibles[:len(nuevas_muestras)]\n",
    "nuevas_muestras['instant_date'] = nuevas_fechas_asignadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efb3ac71-2858-430b-859e-976b40e52f72",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "nuevas_fechas_asignadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "448f0562-a5d4-43a4-bf31-0b07ba99a758",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "nuevas_muestras.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42207b6e-f3bf-4b46-acdc-7d77e2d80703",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Solo se han de agregar las etiquetas que tienen la clase minoritaria en este caso 0\n",
    "nuevas_muestras['congestion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65179d95-e481-4a1c-ab6b-64e530823623",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Crear el DataFrame final combinando los datos originales y las nuevas muestras\n",
    "nuevas_muestras.set_index('instant_date', inplace=True)\n",
    "datos_balanceados = pd.concat([datos, nuevas_muestras[['congestion']]]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f427f774-5d8f-4d58-9d68-5464cb6cc074",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af7ce252-33a1-464e-9fa9-dd967d30a69d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 3. Hacer el Balanceo de datos mediante SMOTE (aumentando la clase minoritoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83bcc5a7-6a7c-464d-bbfa-4e145ec42fee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Convertimos a index la fecha\n",
    "datos = datos.set_index('instant_date_t')\n",
    "\n",
    "# Filtrar las fechas donde congestion == 1\n",
    "fechas_congestion_1 = datos[datos['congestion'] == 1].index\n",
    "\n",
    "# Generar un rango de fechas completo dentro del rango del DataFrame\n",
    "fecha_min = datos.index.min()\n",
    "fecha_max = datos.index.max()\n",
    "rango_completo = pd.date_range(start=fecha_min, end=fecha_max, freq='S')\n",
    "\n",
    "# Excluir las fechas de congestion == 1 del rango completo\n",
    "fechas_disponibles = rango_completo.difference(fechas_congestion_1)\n",
    "\n",
    "# Aplicar SMOTE para generar nuevas muestras de la clase minoritaria (congestion == 0)\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# Usar todas las columnas como características para SMOTE excepto 'congestion'\n",
    "X = datos.drop(columns=['congestion'])\n",
    "y = datos['congestion']\n",
    "\n",
    "# Convertir las fechas del índice a números para usarlas con SMOTE\n",
    "X['instant_date_num'] = X.index.astype(int) / 10**9  # Convertir a segundos\n",
    "\n",
    "# Aplicar SMOTE\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "# Convertir de nuevo a DataFrame\n",
    "X_res = pd.DataFrame(X_res, columns=X.columns)\n",
    "y_res = pd.Series(y_res, name='congestion')\n",
    "\n",
    "# Filtrar las nuevas muestras generadas por SMOTE (la diferencia entre las originales y las nuevas)\n",
    "nuevas_muestras = X_res[len(datos):]\n",
    "nuevas_congestion = y_res[len(datos):]\n",
    "\n",
    "# Asignar nuevas fechas secuenciales de fechas_disponibles a las nuevas muestras\n",
    "nuevas_fechas_asignadas = fechas_disponibles[:len(nuevas_muestras)]\n",
    "nuevas_muestras['instant_date'] = nuevas_fechas_asignadas\n",
    "\n",
    "# Crear el DataFrame final combinando los datos originales y las nuevas muestras\n",
    "nuevas_muestras = nuevas_muestras.set_index('instant_date')\n",
    "nuevas_muestras = nuevas_muestras.drop(columns=['instant_date_num'])\n",
    "nuevas_muestras['congestion'] = nuevas_congestion.values\n",
    "\n",
    "# Combinar los datos originales y las nuevas muestras\n",
    "datos_balanceados = pd.concat([datos, nuevas_muestras]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3f8c4bb-a2cc-4a63-9ddd-be71e8808975",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_balanceados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fa2ecb4-ee0d-4f4e-a552-c8e8aeb08ec7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#### Verificamos si se hizo el Balanceo adecuadamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adcb712a-412e-4564-a88c-2b0b5a408d8d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(datos_balanceados['congestion'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c82dbf96-a171-4639-93ce-cc7d97fdc939",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 3.1 Verificamos la peridocidad entre nuestra serie temporal, si hay periocidad exacta, o es por distintas periocidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "096dc123-294c-4656-9ee3-d6af09dc2f98",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#2.3 Ordenamos el dataset de forma ascendente segun el datetime\n",
    "datos_balanceados.sort_index(inplace=True)\n",
    "\n",
    "#2.4 Identificamos la periocidad de la serie temporal\n",
    "df_time_diffs = datos_balanceados.index.to_series().diff().dt.total_seconds()\n",
    "\n",
    "# # 2.4.1 Contar cuántas diferencias de tiempo tienen cada valor específico\n",
    "diferencias_frecuencias = df_time_diffs.value_counts().sort_index()\n",
    "# # 2.4.2 Mostrar los recuentos\n",
    "print(diferencias_frecuencias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60c7c55d-1cf4-4c9e-973b-5020c5ed13e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SHOW DATABASES\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c012bea5-76e2-4034-91de-c3b26647acd2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Resetear el índice de Pandas y renombrarlo como \"fecha_hora\"\n",
    "datos_balanceados.reset_index(inplace=True)\n",
    "datos_balanceados.rename(columns={\"index\": \"instant_date_t\"}, inplace=True)\n",
    "\n",
    "# Convertir el DataFrame de Pandas a un DataFrame de Spark\n",
    "spark_datos = spark.createDataFrame(datos_balanceados)\n",
    "\n",
    "# Nombre de la tabla Delta a guardar\n",
    "nombre_tabla_delta = \"dbproyectocongestion_presentation.data_congestion_serietemp_balanceada\"\n",
    "\n",
    "# Verificar si ya existe la tabla Delta\n",
    "if spark.catalog.tableExists(nombre_tabla_delta):\n",
    "    # Eliminar la tabla Delta existente\n",
    "    spark.sql(\"DROP TABLE IF EXISTS \" + nombre_tabla_delta)\n",
    "\n",
    "# 12. Guardar los datos preprocesados en una tabla Delta\n",
    "spark_datos.write.format(\"delta\").mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(nombre_tabla_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e30b4a3-b571-4c68-9bd2-78226fd704db",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 3.2 Uniformizamos la periocidad de la serie temporal, a la deseada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a59e576-80f6-43a2-9733-38079583624b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Leemos los datos de PRESENTATION la tabla Delta con los datos Balanceados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2887a523-f06d-4d53-a1ce-b91e2f8fa5e7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#1. Leemos los datos de PROCEESED la tabla Delta \n",
    "df_delta2 = spark.read.format(\"delta\").load(\"/mnt/datalakemlopsd4m/presentation/proyectocongestion_presentation/data_congestion_serietemp_balanceada\")\n",
    "datos_cong_balanceado = df_delta2.toPandas()\n",
    "datos_cong_balanceado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6980f091-62c2-4262-9444-97e67213a49f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(datos_cong_balanceado['congestion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42b8597f-2ece-48cd-877d-f7e85a05e33c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_cong_balanceado.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df088d15-f5cc-4fea-a165-6bbb1a96cc66",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# #2. Ajuste de los datos a Series Temporales\n",
    "# #2.1 Se establece la columna 'Time' como el índice del DataFrame \"datos\"\n",
    "datos_cong_balanceado = datos_cong_balanceado.set_index('instant_date_t')\n",
    "\n",
    "# #2.3 Ordenamos el dataset de forma ascendente segun el datetime\n",
    "datos_cong_balanceado.sort_index(inplace=True)\n",
    "\n",
    "#2.4 Identificamos la periocidad de la serie temporal\n",
    "df_time_diffs = datos_cong_balanceado.index.to_series().diff().dt.total_seconds()\n",
    "\n",
    "# # 2.4.1 Contar cuántas diferencias de tiempo tienen cada valor específico\n",
    "# diferencias_frecuencias = df_time_diffs.value_counts().sort_index()\n",
    "# # 2.4.2 Mostrar los recuentos\n",
    "# print(diferencias_frecuencias)\n",
    "\n",
    "#3. Eliminamos o Filtramos las filas donde la diferencia es distinta de cero (Con ello eliminamos las filas o registros de fechas duplicadas)\n",
    "datos_cong_balanceado = datos_cong_balanceado[df_time_diffs != 0]\n",
    "\n",
    "#4. # Reinterpolar el dataset con una periosidad en especifico\n",
    "# 'S' o 'seg' : Segundo, 'T' o 'min': Minuto,'H' o 'Hr': Hora,'D': Día,'W': Semana,'M': Mes,'Q': Trimestre,'Y': Año\n",
    "datos_cong_balanceado = datos_cong_balanceado.asfreq(freq='5T', method='bfill')\n",
    "\n",
    "datos_cong_balanceado.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76f26087-e5dd-4070-9326-62a84006c007",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 3.3 Verificamos los en cuantos datos nos quedamos luego de uniformizar la periocidad de la serie temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "701d3013-5039-4ddd-96ec-3f5a4636fc45",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_cong_balanceado['congestion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29997d90-13c1-42b0-be4e-8a0c91c25e18",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_time_diffs2 = datos_cong_balanceado.index.to_series().diff().dt.total_seconds()\n",
    "\n",
    "# # 2.4.1 Contar cuántas diferencias de tiempo tienen cada valor específico\n",
    "diferencias_frecuencias2 = df_time_diffs2.value_counts().sort_index()\n",
    "# # 2.4.2 Mostrar los recuentos\n",
    "print(diferencias_frecuencias2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d50538c-19ab-4fb1-8d79-e10a12311162",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Verificar si hay valores nulos en el DataFrame\n",
    "valores_nulos = datos_cong_balanceado.isnull().sum()\n",
    "valores_nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "903a2a6e-e341-4ea8-bf9a-76a0257b3ee9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_cong_balanceado.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "313cca4c-5a11-4d31-96f1-c4a17dca81af",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4. Modelos de Machine learning en Problemas de Series Temporales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36cc9402-7ef4-4c34-8823-babf0c765457",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 4.1 Modelo Forecaster LGBM(Light Gradient Boosting Machine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "29a21013-7568-4e9d-87fd-e252bbc24b57",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    " 4.1.1 Separacion de los datos en Train-Validation-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b87fc4cb-7dd0-4991-b0fd-4c71fa449089",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_cong_balanceado.index.min(),datos_cong_balanceado.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf3cce13-4bb4-4ae0-9f5a-4d054a52c181",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Separacion de los datos en Train-Validation-Test\n",
    "datos_cong_balanceado = datos_cong_balanceado.loc['2024-03-27 01:15:28' : '2024-04-23 23:59:30']\n",
    "fin_train = '2024-04-15 23:59:30'\n",
    "fin_validacion = '2024-04-19 23:59:30'\n",
    "datos_train = datos_cong_balanceado.loc[:fin_train, :] #20 dias\n",
    "datos_val = datos_cong_balanceado.loc[fin_train:fin_validacion, :] #5 dias\n",
    "datos_test = datos_cong_balanceado.loc[fin_validacion: , :] # 5 dias\n",
    "\n",
    "print(f\"Fechas train: {datos_train.index.min()} ... {datos_train.index.max()} (n={len(datos_train)})\")\n",
    "print(f\"Fechas validacion: {datos_val.index.min()} ... {datos_val.index.max()} (n={len(datos_val)})\")\n",
    "print(f\"Fechas test: {datos_test.index.min()} ... {datos_test.index.max()} (n={len(datos_test)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "798d5c80-f47e-4961-be13-5c6db1ea6ac0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(datos_train.shape,datos_val.shape, datos_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6e06a6d-95f2-43a0-a0a9-5a135dbe3485",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "4.1.2 Exploracion Grafica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d87f9d5-4ef6-49fc-9a1c-b096c757fad5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Grafico de la serie temporal\n",
    "\n",
    "#crea una nueva figura y un par de ejes (axes) dentro de la figura\n",
    "fig, ax = plt.subplots(figsize=(15,4)) # figsize=(15,4) establece el tamaño de la figura en 15 unidades de ancho y 4 unidades de alto.\n",
    "\n",
    "#Las series se colorean automáticamente según una paleta de colores predefinida por matplotlib\n",
    "datos_train.congestion.plot(ax=ax, label=\"entrenamiento\", linewidth=1)\n",
    "datos_val.congestion.plot(ax=ax, label=\"validacion\", linewidth=1)\n",
    "datos_test.congestion.plot(ax=ax, label=\"test\", linewidth=1)\n",
    "ax.set_title('Congestion ')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "49b0f92f-667b-4e10-9f10-eb74895f45c2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "4.1.3 Grafico de Autocorrelacion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f91801e-2243-4992-a6a2-f4b1042083ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Grafico autocorrelación\n",
    "\n",
    "#Crea una figura y un conjunto de ejes (ax)\n",
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "\n",
    "#Aquí utilizamos la función plot_acf para trazar la función de autocorrelación\n",
    "#ax=ax indica que el gráfico se dibujará en los ejes que has creado anteriormente. \n",
    "# lags=72 define el número máximo de intervalos de tiempo pasados que se considerarán al calcular la función de autocorrelación. \n",
    "plot_acf(datos_cong_balanceado.congestion, ax=ax, lags=800)\n",
    "plt.show()\n",
    "\n",
    "#Podemos ver que la correlacion de la prediccion esta altamente correlaciona con el la demanda en el dia anterior a la misma hora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "081df00d-5f53-4bbb-8427-0160ea26a304",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Grafico de Autocorrelacion parcial\n",
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "\n",
    "#plot_pacf para trazar la función de autocorrelación parcial\n",
    "plot_pacf(datos_cong_balanceado.congestion, ax=ax, lags=60)\n",
    "\n",
    "# PACF muestra la correlación directa entre la serie y sus \n",
    "# valores anteriores hasta 60 intervalos de tiempo atrás, teniendo en cuenta las correlaciones indirecta\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "789cd064-fa69-4218-94a5-b95050240074",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#### 4.1.4 Algoritmo de LGBM(Ligth Bosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e83fed6-fbbe-40fa-9ae3-b3a1447398bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Modelado y Forescasting\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier    #Regressor mas potente de gradient bossting\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg  # Modelo autoregressivo\n",
    "from skforecast.model_selection import grid_search_forecaster # Encontrar los mejores hiperparametros(optimizar el modelo)\n",
    "from skforecast.model_selection import backtesting_forecaster # Evaluar el modelo si hubiese estado en produccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71995d13-5519-46c0-bebe-fa5b154b6b75",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Crear  y entrenar forescaster\n",
    "forescaster = ForecasterAutoreg(\n",
    "    regressor=LGBMClassifier(max_depth=3, learning_rate=0.1, n_estimators=70),\n",
    "    lags= 5 #[1, 2, 3, 24]\n",
    ")\n",
    "forescaster #forescaster.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43a3bf28-cfeb-4f25-a851-796505bb02ff",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Entrenamiento del Forescaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1601003f-951b-408e-91dc-9054a666bb86",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "forescaster.fit(y=datos_cong_balanceado.loc[:fin_validacion, 'congestion']) #Entrenamiento con conjuntos de train + validacion\n",
    "forescaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "774b2a40-7c7d-4e3f-a6ca-e9ffc0f15244",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da051d6c-63a3-4705-ab51-bb7ae0e6f5ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predicciones = forescaster.predict(steps=1000)\n",
    "predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da19cc22-d028-4314-9fda-d2747dff1154",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "forescaster.last_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49eb2ea3-27f4-4b51-bf3c-839da8a4877e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Obtener las probabilidades para las predicciones\n",
    "probabilidades = forescaster.regressor.predict_proba(forescaster.last_window.values.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c4cd860-7b80-4255-adbc-ad1b14f577d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3a5f67c-796a-4a28-a5c3-0c5bbde65520",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Inicializar una lista para almacenar las probabilidades para cada predicción\n",
    "probabilidades_predicciones = []\n",
    "\n",
    "# Iterar sobre las predicciones y obtener las probabilidades para cada una\n",
    "for pred in predicciones:\n",
    "    # Obtener las probabilidades para la predicción actual\n",
    "    proba = forescaster.regressor.predict_proba(forescaster.last_window.values.reshape(1, -1))\n",
    "    probabilidades_predicciones.append(proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "570c2c64-352c-4e06-97af-29166283b032",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "probabilidades_predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e2954f5-476e-42c7-a805-b6addb091d1e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 4.1.5 Algoritmo Time Series Forest Clasification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48c85e46-fbef-4713-9618-2f12ab648acd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#!pip install sktime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7d7d97b-b34e-45ba-8c08-d2d53c1ea759",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14ab4732-7a0d-4d63-8f34-3ea72b713dc2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
    "from sktime.datasets import load_arrow_head\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4742a442-83c9-439e-8f9e-0fe6647bbe11",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_cong_balanceado.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee97788b-5671-4e3a-8079-866d7ebb2230",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Seleccionamos la variable target y las variables predictoras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74bb69a8-2876-46fc-9ad5-ca61267c07e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Reformatear los datos en un formato compatible con sktime\n",
    "X = datos_cong_balanceado[['x', 'y']].values.reshape(-1, 1, 2)\n",
    "\n",
    "# Tomar las etiquetas objetivo (y) como una serie temporal\n",
    "y = datos_cong_balanceado['congestion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "992612b1-871f-458e-9438-0c579ea81925",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Ultimos registros del numpy array\n",
    "X[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3cb18e6-0ce7-47c4-a0d0-463c68783543",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Primeros registros del numpy array\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70bce45f-39a5-4cc7-8669-34f4c6f41589",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6572bd85-dab3-430f-9cc7-0d0764b1e761",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Entrenamiento del Modelo ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c74c305-434b-4852-b71e-3fed1f3c83d0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fechas = datos_cong_balanceado.index\n",
    "# Dividir los datos en conjunto de entrenamiento y conjunto de prueba\n",
    "X_train, X_test, y_train, y_test, fechas_train, fechas_test = train_test_split(X, y, fechas, test_size=0.2, shuffle=False)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False) # shuffle=False, los datos no se mezclarán y se dividirán #secuencialmente según el orden en el que aparecen en tus datos (adecuado para problemas de series temporales)\n",
    "classifier = TimeSeriesForestClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred_probability = classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e85480c7-8d32-450e-856c-c00ddd7467ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fechas_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "391228c0-f6eb-42db-be67-94b3f332fa74",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "714abf6d-eea6-4208-a325-73c349cb68a2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12b4d079-48cb-48d7-98a3-cb81dd9fd78e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e14b5ad-9e5d-4ada-a8d0-d24c04fc76de",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Solo nos quedamos con la columna de la derecha, Donde seria (Probabilidad de que suceda la \"Clase 1\" en este caso SI HAY CONGESTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72e0dc8f-7026-4209-ba38-efa37299b2e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Suponiendo que y_pred_probability es tu matriz de probabilidades\n",
    "y_pred_columna_derecha = y_pred_probability[:, 1]\n",
    "\n",
    "# Establecer la opción de impresión para mostrar el array completo\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# Imprimir el array completo de probabilidades\n",
    "print(y_pred_columna_derecha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "375104b8-156f-4ae2-b600-bdc9734000eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e63ab3e-4ea2-4460-80cd-ce3f28496f93",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Crea la figura con el tamaño especificado\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Graficar las predicciones\n",
    "plt.plot(fechas_test, y_test, linestyle='-', marker='o', color='blue', label='Real')\n",
    "plt.plot(fechas_test, y_pred_columna_derecha, linestyle='--', marker='x', color='red', label='Predicción')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Valor')\n",
    "plt.title('Comparación entre Real y Predicción')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16ddcb22-8a18-44cf-985c-e5370480fd10",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Crea la figura con el tamaño especificado\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Graficar las predicciones\n",
    "plt.plot(fechas_test, y_test, linestyle='-', marker='o', color='blue', label='Real')\n",
    "plt.plot(fechas_test, y_pred, linestyle='--', marker='x', color='red', label='Predicción')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Valor')\n",
    "plt.title('Comparación entre Real y Predicción')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d45d042-baa4-44ff-8360-c73a78c2cd26",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_cong_balanceado.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c090427-f3a1-43cb-acb6-cf458e3d4110",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "window_size = 5\n",
    "\n",
    "# Seleccionar solo las variables específicas que deseas incluir en X_future\n",
    "variables_seleccionadas = ['x', 'y']\n",
    "\n",
    "# Obtener las últimas observaciones de las variables seleccionadas\n",
    "X_future = datos_cong_balanceado.tail(window_size)[variables_seleccionadas].values\n",
    "\n",
    "X_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be8e4060-1eba-4971-9804-cc518cabf42d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "len(X_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0e8798f-683a-4e7b-9264-1e5df6c4e917",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_future[2:2+window_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1825146d-a3ac-401c-99e7-b7ad528d9acf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_window2 = X_future[4:4+window_size]\n",
    "X_window2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a26bd8a-2093-44c0-a37e-c6d89bfa23f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_window2.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "501f9536-aded-44c9-82eb-0de7aa6f4e5e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_cong_balanceado.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "990bbe83-29a5-4e3b-8499-c2b7fa1df11a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Obtener los últimos cinco pasos anteriores de las dos variables para el pronóstico\n",
    "window_size = 5\n",
    "X_future = datos_cong_balanceado.tail(window_size).values\n",
    "\n",
    "# Realizar el pronóstico para cada paso de tiempo futuro\n",
    "y_pred_future = []\n",
    "\n",
    "for i in range(len(X_future)):\n",
    "    # Obtener las últimas cinco observaciones de las dos variables\n",
    "    X_window = X_future[i:i+window_size]\n",
    "    \n",
    "    # Realizar la predicción de congestión con el clasificador entrenado\n",
    "    congestion_pred = classifier.predict_proba(X_window.reshape(1, -1))\n",
    "    \n",
    "    # Agregar la predicción a la lista de pronósticos futuros\n",
    "    y_pred_future.append(congestion_pred)\n",
    "\n",
    "# Convertir la lista de pronósticos futuros en un arreglo numpy\n",
    "y_pred_future = np.array(y_pred_future)\n",
    "# Suponiendo que y_pred_probability es tu matriz de probabilidades\n",
    "y_pred_future = y_pred_future[:, :, 1]\n",
    "# Visualizar las predicciones futuras\n",
    "print(\"Predicciones futuras de congestión:\", y_pred_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "307e4a2a-55ba-44c4-b356-d1e989c6f565",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "len(X_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a0ef83d-4cdd-4c86-93d8-7687df29272b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Preparar una lista para almacenar las predicciones futuras\n",
    "y_pred_future2 = []\n",
    "\n",
    "# Definir el tamaño de la ventana de predicción futura\n",
    "window_size2 = 1  # Por ejemplo, predecir los próximos 5 pasos\n",
    "\n",
    "variables_seleccionadas = ['x', 'y']\n",
    "\n",
    "# Obtener las últimas observaciones de las variables seleccionadas\n",
    "X_future = datos_cong_balanceado.tail(window_size)[variables_seleccionadas].values\n",
    "\n",
    "#X_future = datos_cong_balanceado.tail(window_size).values\n",
    "\n",
    "# Iterar a través de tus datos futuros\n",
    "for i in range(len(X_future) - window_size2 + 1):\n",
    "    # Obtener la ventana de datos actual\n",
    "    X_window = X_future[i:i+window_size]\n",
    "    \n",
    "    # Realizar la predicción de congestión con tu modelo clasificador\n",
    "    congestion_pred = classifier.predict_proba(X_window.reshape(1, -1))  # Ajustar la forma según tu modelo\n",
    "    \n",
    "    # Tomar solo la última predicción y agregarla a la lista\n",
    "    y_pred_future2.append(congestion_pred[-1])\n",
    "\n",
    "# Convertir la lista de predicciones en un arreglo numpy\n",
    "y_pred_future2 = np.array(y_pred_future2)\n",
    "# Suponiendo que y_pred_probability es tu matriz de probabilidades\n",
    "y_pred_future2 = y_pred_future2[:, 1]\n",
    "\n",
    "# Visualizar las predicciones\n",
    "print(\"Predicciones futuras:\", y_pred_future2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be01f69d-a563-4af9-bcfb-dd92b8a009ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_cong_balanceado.tail(10).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e148abe-cefb-4430-a2ea-9de5c2780aab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_cong_balanceado.tail(2)[variables_seleccionadas].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "636a4a8b-0bcf-4c6d-8cd9-9e4c0f9bd874",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "variables_seleccionadas = ['x', 'y','z']\n",
    "\n",
    "# Obtener las últimas observaciones de las variables seleccionadas\n",
    "X_future_single_step = datos_cong_balanceado.tail(1)[variables_seleccionadas].values\n",
    "\n",
    "# Realizar la predicción para un solo paso hacia adelante\n",
    "congestion_pred_single_step = classifier.predict_proba(X_future_single_step)\n",
    "\n",
    "\n",
    "# Visualizar la predicción\n",
    "print(\"Probabilidad de congestión para el próximo paso:\", congestion_pred_single_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59a39e08-dee6-4a2d-9890-80bdfe6cb3e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_future_single_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6f611d4-f8de-41fa-8f94-ffc636f3b633",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ff5ed8b-2087-49b5-bb70-3e42b11ad295",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Supongamos que tienes tus datos de series temporales en X_time_series y tus variables exógenas en X_exogenous\n",
    "# Supongamos que tienes tus etiquetas en y\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train_ts, X_test_ts, X_train_exog, X_test_exog, y_train, y_test = train_test_split(X_time_series, X_exogenous, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Crear una matriz DMatrix para XGBoost\n",
    "train_dmatrix = xgb.DMatrix(data=X_train_ts, label=y_train)\n",
    "test_dmatrix = xgb.DMatrix(data=X_test_ts)\n",
    "\n",
    "# Definir los parámetros del modelo\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # para problemas de clasificación binaria\n",
    "}\n",
    "\n",
    "# Entrenar el modelo XGBoost\n",
    "model = xgb.train(params=params, dtrain=train_dmatrix)\n",
    "\n",
    "# Realizar predicciones de probabilidades de clase\n",
    "y_pred_probs = model.predict(test_dmatrix)\n",
    "\n",
    "print(\"Predicciones de probabilidades de clase:\", y_pred_probs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e54c22dc-b404-4713-ae69-e813ca603cbf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Algoritmo XGB Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94172134-ad96-4a76-85e1-82b902b0d02f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72eafbc6-b0ad-4284-9ea3-b8c6e2a340d3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_cong_balanceado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e47cc3f3-9a17-4322-9f5d-d3fab20e0aef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "FEATURES = ['x','y','bearing_t','speed_t']\n",
    "\n",
    "x = datos_cong_balanceado[FEATURES]\n",
    "y = datos_cong_balanceado['congestion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a388978-a228-4c25-806c-fb12846db6c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y conjunto de prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=False, random_state=1)\n",
    "#shuffle=False, los datos no se mezclarán y se dividirán #secuencialmente según el orden(ideal para time series)\n",
    "\n",
    "# Generamos los datasets de train y test\n",
    "train  = pd.concat([X_train,y_train], axis=1)\n",
    "test  = pd.concat([X_test,y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02cdfb74-fd23-4286-8e50-ebf7e46a5111",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0079037-6d60-4bb8-b92d-731edf696fe8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(n_estimators=300,max_depth=5,objective='binary:logistic',reg_alpha=0.1) #reg_alpha>>regulazrizacion Lasso educir la complejidad del modelo y evitar #el sobreajuste\n",
    "#eval_set>>monitorear el rendimiento del modelo en los datos de evaluación durante el #entrenamiento\n",
    "#objective='binary:logistic'> Para problemas de clasificacion binaria\n",
    "\n",
    "xgb_model.fit(X_train,y_train,eval_set=[(X_train,y_train), (X_test,y_test)],eval_metric=['auc','error'],\n",
    "              early_stopping_rounds=50,verbose=True)\n",
    "#verbose=True >> Mostrar en pantalla las iteraciones\n",
    "#'auc'>>AUC es una métrica que evalúa la capacidad del modelo para distinguir entre clases positivas y negativas\n",
    "# 'error'>> cuanto se equivoca el modelo en predecir (100-error)\n",
    "# logloss>>un logloss más bajo indica un mejor rendimiento del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e678d4cd-4d25-45bc-bc97-84965088c290",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa732a29-5b26-4f65-b842-e12d4c1633e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "f1 = pd.DataFrame(data=xgb_model.feature_importances_,index=xgb_model.feature_names_in_,columns=['importantes/variables'])\n",
    "\n",
    "f1.sort_values('importantes/variables').plot(kind='barh',title='Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f28b6726-e5b0-48fb-b307-56f29ce620f3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "y_pred_prob = xgb_model.predict_proba(X_test)\n",
    "y_pred_prob = np.round(y_pred_prob,3)\n",
    "y_pred_prob = y_pred_prob[:, 1]  # Filtramos columna derecha, para dejar probabilidad que suceda CLASE 1(Conges)\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Establecer la opción de impresión para mostrar el array completo\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b53aa0c-1b2e-4d0a-a124-2e7fd41b2cbf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a17d9635-6b94-4ee2-b5df-65c6abe1e942",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Armamos nuetros datos para graficar las serie temporal original vs prediccion en el periodo de datos de Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3294b1e4-e326-47b8-bca9-d5ef9c1610b4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test[\"prediction-prob\"] = y_pred_prob  #y_pred en dimension 1d\n",
    "test[\"prediction\"] = y_pred  #y_pred en dimension 1d\n",
    "datos_cong_balanceado = datos_cong_balanceado.merge(test[['prediction-prob','prediction']], how='left', left_index=True,right_index=True) #left_index=True, right_index=True > la fusión se realizará basándose índices de las filas\n",
    "datos_cong_balanceado.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b70cb38-e1b6-4a23-8908-20f7c198c9a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ax = datos_cong_balanceado[['congestion']].plot(figsize=(15,5)) #crea un gráfico de la columna 'congestion_x' del DF\n",
    "\n",
    "# Se utiliza el ax=ax especifica que esta serie debe agregarse al mismo gráfico que se creó anteriormente\n",
    "datos_cong_balanceado['prediction-prob'].plot(ax=ax, style='.') #style='.'\n",
    "plt.legend(['Original','Prediction'])\n",
    "ax.set_title('Time Series XGB')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fea0afae-5a39-4acf-9002-a859f15357ba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f4c2281-3ff7-45b4-98cb-dc4c92ca7f2e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ax = datos_cong_balanceado.loc[(datos_cong_balanceado.index > '2024-04-18 09:50:28') & (datos_cong_balanceado.index < '2024-04-22 09:50:28')]['congestion'].plot(figsize=(15,5), title='Data Semanal')\n",
    "datos_cong_balanceado.loc[(datos_cong_balanceado.index > '2024-04-18 09:50:28') & (datos_cong_balanceado.index < '2024-04-22 09:50:28')]['prediction-prob'].plot(style='.')\n",
    "plt.legend(['Original','Prediction-prob'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "768822a7-f47c-4565-b8c2-96b67a4f80d2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Medimos el Performance del Modelo (En este caso con Accuracy, por ser un modelo de Clasificacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ea0c6ec-ad86-4049-8d8d-dcba7e48af83",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89a03d8c-8325-46b8-8efe-694fb4cb7e9d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn import metrics\n",
    "names = ['sin_congestion','congestion']  #Aqui se especifica los nombres de las clases >  En orden desde 0>Sin congestion  1>Congestion, 2>etc, etc\n",
    "matriz_confusion = confusion_matrix(y_test, y_pred)  #Poner el orden> Clase real , clase predicha\n",
    "print(metrics.classification_report(y_test,y_pred, digits=4))\n",
    "plot_confusion_matrix(conf_mat=matriz_confusion, figsize =(4,4), class_names=names, show_normed=False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84ff92ca-06f5-4a44-80e4-1146e60108b4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Outlier Removal of Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "667307de-4615-42f0-86ee-8424343700c0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_cong_balanceado['congestion'].plot(style='.',\n",
    "                        figsize=(15,5),                       \n",
    "                        title='Congestion Time Serie')                 \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ec16742-fb8b-4f1d-8764-2a312f5dbb9d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Analisis de Outliers (Histograma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fcd8d60-247f-4348-9fc5-ce312411922b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_cong_balanceado['congestion'].plot(kind='hist', bins=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a55a92b3-10ff-4c17-b65f-0acf810cd629",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "1. Time Series Croos Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02e23ead-68e3-483b-b4ff-21efcf15ab9f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_cong_balanceado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e79e5b44-a2e7-4217-9a8f-1d6094933708",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "#Se construye el Generador del CROSS VALIDATION\n",
    "tss = TimeSeriesSplit(n_splits=5, test_size=24*1, gap=24)\n",
    "#24*365*1 : por ejemplo quieres predecir 1 año\n",
    "\n",
    "#ordenamos la secuencia para un problema de serie temporal\n",
    "datos_cong_balanceado = datos_cong_balanceado.sort_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5bfa9be-9f1c-4865-99b1-450f32a2dd54",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Generamos los subgraficos para los tramos del Croos Validation, en este caso (Hemos partido en 5 partes)\n",
    "fig, axs = plt.subplots(5, 1, figsize=(15,15), sharex=True)\n",
    "\n",
    "#Inicializamos el contador, para movernos en los tramas\n",
    "fold = 0\n",
    "#Aplicamos el generador de CROSS VALIDATION\n",
    "for train_idx , val_idx in tss.split(datos_cong_balanceado):\n",
    "    train2 = datos_cong_balanceado.iloc[train_idx]\n",
    "    test2 = datos_cong_balanceado.iloc[val_idx]\n",
    "    train2['congestion'].plot(ax=axs[fold],\n",
    "                                label='Train Set',\n",
    "                                title=f'Data Train/Test Split Fold {fold}')\n",
    "    test2['congestion'].plot(ax=axs[fold],\n",
    "                                label='Test Set')\n",
    "    axs[fold].axvline(test2.index.min(), color='black', ls='--')\n",
    "    fold += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43b43f49-bc0a-44ce-ac63-1ad343fcfc61",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "val_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3cbd9a62-4152-4d21-919f-ed516def452d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "2. Forecasting Horizon Explaind\n",
    "- El horizonte de pronóstico es la longitud de tiempo en el futuro para la cual se preparan los pronósticos. Estos generalmente varían desde horizontes de pronóstico a corto plazo (menos de tres meses) hasta a largo plazo (más de dos años)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2db7489-9337-41e3-bc71-3a98d9202d70",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_cong_balanceado[['x','y','bearing_t','speed_t']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0dea677c-8ecd-4629-8a7c-cb5d87cbdb45",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "3. Lag Features (Funciones de Retraso)\n",
    "- What was the target (x) days in the past (¿Cuál era el objetivo (x) días en el pasado?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1625a1fe-3a29-4676-807c-992b804c2b96",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_cong_balanceado['congestion'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "014e7ab7-3a6d-4995-971d-10b641e7608b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "target_map = datos_cong_balanceado['congestion'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d90ff36-cf9b-4c8b-ae3f-c6daaebdbad5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_cong_balanceado.index.min(), datos_cong_balanceado.index.max(), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d63977a-d61b-4f61-b010-2b9b0e4c0b97",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def add_lags(df):\n",
    "    #Hacemos un diccionario con los valores del TARGET, para completar luego\n",
    "    target_map = datos_cong_balanceado['congestion'].to_dict()\n",
    "\n",
    "    #datos_cong_balanceado['lag1'] = (datos_cong_balanceado.index - pd.Timedelta('1 days')).map(target_map)  #Retroceso 1, en este caso (1 dia)\n",
    "    datos_cong_balanceado['lag1'] = (datos_cong_balanceado.index - pd.Timedelta('5T')).map(target_map)  #Retroceso 1, en este caso (1 dia)\n",
    "    datos_cong_balanceado['lag2'] = (datos_cong_balanceado.index - pd.Timedelta('10T')).map(target_map)  #Retroceso 2, en este caso (2 dia)\n",
    "    datos_cong_balanceado['lag3'] = (datos_cong_balanceado.index - pd.Timedelta('15T')).map(target_map)  #Retroceso 3, en este caso (3 dia)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "266e7e01-bd8d-40dc-b8b8-b93db2bff576",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Eliminar las columnas 'columna1' y 'columna2'\n",
    "#datos_cong_balanceado.drop(['lag1', 'lag2'], axis=1, inplace=True)\n",
    "\n",
    "# axis=1 especifica que las columnas deben ser eliminadas\n",
    "# inplace=True modifica el DataFrame original en su lugar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "030648fa-fcce-4045-b29d-5c57ce422526",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_cong_balanceado = add_lags(datos_cong_balanceado)\n",
    "datos_cong_balanceado.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7c5a44a-c6d4-4233-b0c0-f2ab6df95365",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Entrenar el Modelo Usando Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28a85999-23c6-4eed-8ebb-43b5e8d3679c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    #Create time series features based on time series index\n",
    "    df = df.copy()\n",
    "    df['hora'] = df.index.hour\n",
    "    df['minuto'] = df.index.min\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6232350-316a-4a6d-8f7f-1045f0f0cc07",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "#Se construye el Generador del CROSS VALIDATION\n",
    "tss = TimeSeriesSplit(n_splits=5, test_size=24*1, gap=24)\n",
    "#24*365*1 : por ejemplo quieres predecir 1 año\n",
    "\n",
    "#ordenamos la secuencia para un problema de serie temporal\n",
    "datos_cong_balanceado = datos_cong_balanceado.sort_index() \n",
    "\n",
    "#Inicializamos el contador, para movernos en los tramas\n",
    "fold = 0\n",
    "preds = []\n",
    "scores = []\n",
    "\n",
    "#Aplicamos el generador de CROSS VALIDATION\n",
    "for train_idx , val_idx in tss.split(datos_cong_balanceado):\n",
    "    train2 = datos_cong_balanceado.iloc[train_idx]\n",
    "    test2 = datos_cong_balanceado.iloc[val_idx]\n",
    "    \n",
    "    train2 = create_features(train2)\n",
    "    test2 = create_features(test2)\n",
    "\n",
    "    FEATURES = ['x','y','bearing_t','speed_t','lag1', 'lag2', 'lag3']\n",
    "    TARGET = 'congestion'\n",
    "\n",
    "    X_train2 = train2[FEATURES]\n",
    "    y_train2 = train2[TARGET]\n",
    "\n",
    "    X_test2 = test2[FEATURES]\n",
    "    y_test2 = test2[TARGET]\n",
    "\n",
    "    xgb_model = xgb.XGBClassifier(n_estimators=300,max_depth=5,objective='binary:logistic',reg_alpha=0.1) #reg_alpha>>regulazrizacion Lasso educir la complejidad del modelo y evitar #el sobreajuste\n",
    "    #eval_set>>monitorear el rendimiento del modelo en los datos de evaluación durante el #entrenamiento\n",
    "    #objective='binary:logistic'> Para problemas de clasificacion binaria\n",
    "\n",
    "    xgb_model.fit(X_train2,y_train2,eval_set=[(X_train2,y_train2), (X_test2,y_test2)],eval_metric=['auc','error'],\n",
    "                early_stopping_rounds=50,verbose=True)\n",
    "\n",
    "    y_pred2 = xgb_model.predict(X_test2)\n",
    "    preds.append(y_pred2)\n",
    "    score = np.sqrt(mean_squared_error(y_test2,y_pred2))\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "340f3220-5a33-4078-8a52-1dbab9d83e47",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f'Score acroos folds {np.mean(scores):0.4f}')\n",
    "print(f'Fold scores: {scores}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f595ca4d-24c8-409c-a2e4-26ac154f9e80",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Entrenar el Modelo sin CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "920f1872-39c3-44d8-bfd7-20339cd1db18",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_cong_balanceado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b6d0155-73d0-4319-8624-e0f2fa414bd6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#‘W’, or ‘D’\n",
    "#‘days’, or ‘day’\n",
    "#‘hours’, ‘hour’, ‘hr’, or ‘h’\n",
    "#‘minutes’, ‘minute’, ‘min’, or ‘m’\n",
    "#‘seconds’, ‘second’, ‘sec’, or ‘s’\n",
    "def add_lags(df):\n",
    "    #Hacemos un diccionario con los valores del TARGET, para completar luego\n",
    "    target_map = df['congestion'].to_dict()\n",
    "\n",
    "    #datos_cong_balanceado['lag1'] = (datos_cong_balanceado.index - pd.Timedelta('1 days')).map(target_map)  #Retroceso 1, en este caso (1 dia)\n",
    "    #df['lag1'] = (df.index - pd.Timedelta('5T')).map(target_map)  #Retroceso 1, en este caso (5 minutos)\n",
    "    df['lag1'] = (df.index - pd.Timedelta(25, 'hours')).map(target_map)  #Retroceso 1, en este caso (1 dia)\n",
    "    df['lag2'] = (df.index - pd.Timedelta(32, 'hours')).map(target_map)  #Retroceso 2, en este caso (2 dia)\n",
    "    df['lag3'] = (df.index - pd.Timedelta(40, 'hours')).map(target_map)  #Retroceso 3, en este caso (3 dia)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83431d13-4db1-42a2-822b-d596ce23b64f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_cong_balanceado = add_lags(datos_cong_balanceado)\n",
    "\n",
    "FEATURES = ['x','y','bearing_t','speed_t','lag1', 'lag2', 'lag3','hora','minuto']\n",
    "TARGET = 'congestion'\n",
    "\n",
    "x = datos_cong_balanceado[FEATURES]\n",
    "y = datos_cong_balanceado['congestion']\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y conjunto de prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=False, random_state=1)\n",
    "\n",
    "# Generamos los datasets de train y test\n",
    "train  = pd.concat([X_train,y_train], axis=1)\n",
    "test  = pd.concat([X_test,y_test], axis=1)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=300,max_depth=5,objective='binary:logistic',reg_alpha=0.1) #reg_alpha>>regulazrizacion Lasso educir la complejidad del modelo y evitar #el sobreajuste\n",
    "    #eval_set>>monitorear el rendimiento del modelo en los datos de evaluación durante el #entrenamiento\n",
    "    #objective='binary:logistic'> Para problemas de clasificacion binaria\n",
    "\n",
    "xgb_model.fit(X_train,y_train,eval_set=[(X_train,y_train), (X_test,y_test)],eval_metric=['auc','error'],\n",
    "                early_stopping_rounds=50,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ee922d1-a1cc-47d4-920c-788b974738b5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9570d98c-e0fc-48b3-ba93-1f24502d08d0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "f1 = pd.DataFrame(data=xgb_model.feature_importances_,index=xgb_model.feature_names_in_,columns=['importantes/variables'])\n",
    "\n",
    "f1.sort_values('importantes/variables').plot(kind='barh',title='Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe5d8658-a3b1-4f6c-867a-ef38e3face50",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "y_pred_prob = xgb_model.predict_proba(X_test)\n",
    "y_pred_prob = np.round(y_pred_prob,3)\n",
    "y_pred_prob = y_pred_prob[:, 1]  # Filtramos columna derecha, para dejar probabilidad que suceda CLASE 1(Conges)\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Establecer la opción de impresión para mostrar el array completo\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "234f2415-b4c2-4921-93fd-990fe948d063",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95099deb-2771-4ecb-9743-2070d7994056",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Armamos nuetros datos para graficar las serie temporal original vs prediccion en el periodo de datos de Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9006193c-90a7-49e1-8f48-8e86a043330f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test[\"prediction-prob\"] = y_pred_prob  #y_pred en dimension 1d\n",
    "test[\"prediction\"] = y_pred  #y_pred en dimension 1d\n",
    "datos_cong_balanceado = datos_cong_balanceado.merge(test[['prediction-prob','prediction']], how='left', left_index=True,right_index=True) #left_index=True, right_index=True > la fusión se realizará basándose índices de las filas\n",
    "datos_cong_balanceado.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bd5c3de-0200-47f0-8f8c-53cc94fee4c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ax = datos_cong_balanceado[['congestion']].plot(figsize=(15,5)) #crea un gráfico de la columna 'congestion_x' del DF\n",
    "\n",
    "# Se utiliza el ax=ax especifica que esta serie debe agregarse al mismo gráfico que se creó anteriormente\n",
    "datos_cong_balanceado['prediction-prob'].plot(ax=ax, style='.') #style='.'\n",
    "plt.legend(['Original','Prediction'])\n",
    "ax.set_title('Time Series XGB')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e60fa98-0b70-45d8-b21f-9b693ec4f285",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "769fe2f6-1f57-47df-893d-0fe986178a66",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ax = datos_cong_balanceado.loc[(datos_cong_balanceado.index > '2024-04-18 09:50:28') & (datos_cong_balanceado.index < '2024-04-22 09:50:28')]['congestion'].plot(figsize=(15,5), title='Data Semanal')\n",
    "datos_cong_balanceado.loc[(datos_cong_balanceado.index > '2024-04-18 09:50:28') & (datos_cong_balanceado.index < '2024-04-22 09:50:28')]['prediction-prob'].plot(style='.')\n",
    "plt.legend(['Original','Prediction-prob'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e0f2291-2d86-4ce5-91b8-4dee4e0782f0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Medimos el Performance del Modelo (En este caso con Accuracy, por ser un modelo de Clasificacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7888c1c1-7acb-4a4b-a1d4-4512e9251650",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "168a87a5-7363-4f16-8f80-c91114d6a1a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "names = ['sin_congestion','congestion']  #Aqui se especifica los nombres de las clases >  En orden desde 0>Sin congestion  1>Congestion, 2>etc, etc\n",
    "matriz_confusion = confusion_matrix(y_test, y_pred)  #Poner el orden> Clase real , clase predicha\n",
    "print(metrics.classification_report(y_test,y_pred, digits=4))\n",
    "plot_confusion_matrix(conf_mat=matriz_confusion, figsize =(4,4), class_names=names, show_normed=False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3a8b98a-4361-4819-9962-16036466d661",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "4. Predicting the Future\n",
    "- Reentrenamiento en todos los datos (Entrenar el Modelo con los Lags, si aun no lo has entrenado asi)\n",
    "- Para predecir el futuro, necesitamos un dataframe vacío para rangos de fechas futuras\n",
    "- Ejecutar esas fechas a través de nuestro código de creación de características + creación de rezagos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "190770a3-c3b2-4694-9525-fc7f03fdebc9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_cong_balanceado.index.max() + pd.Timedelta(minutes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa48d2fb-e0dc-4037-ba3a-ddbd882654eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_cong_balanceado.index.max() + pd.Timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57cc4016-4560-4ff7-9869-99dca8ecf412",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "futuretesting=pd.date_range(datos_cong_balanceado.index.max() + pd.Timedelta(minutes=5), datos_cong_balanceado.index.max() + pd.Timedelta(days=1) , freq='5T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4445475f-2268-4597-8e70-fb1e33831948",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "futuretesting[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c6748ce-155d-40a1-b7be-7f8639bc2458",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "futuretesting[0] - pd.Timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f53dbbf5-9211-4f9c-b3b1-c66f42ed5c8b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "futuretesting - pd.Timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ad508f7-c984-489a-8d4a-e3fbb54079d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Creature future dataframe\n",
    "\n",
    "# #1. Creamos el esqueleto del df del Pronostico (con las fecha Inicio y Fin del Pronostico (en este caso 1 dia en el futuro en rango de 5minutos))\n",
    "future=pd.date_range(datos_cong_balanceado.index.max() + pd.Timedelta(minutes=5), datos_cong_balanceado.index.max() + pd.Timedelta(days=1) , freq='5T')\n",
    "future_df=pd.DataFrame(index=future)\n",
    "\n",
    "# #Se agrega la columna de FUTURE en el df pronostico com TRUE (para indicar que son el futuro)\n",
    "future_df['isFuture'] = True\n",
    "\n",
    "# #Se agrega la columna de FUTURE en el df Original con FALSE (para indicar no es futuro) \n",
    "datos_cong_balanceado['isFuture'] = False\n",
    "\n",
    "#Se hace una concatenacion para agregar las filas de future_df al df_original\n",
    "df_and_future = pd.concat([datos_cong_balanceado, future_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2ed9d44-3363-4631-a119-edd2a9fcb90f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_and_future.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "722383e5-2189-47cb-8ced-78734426e696",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "variables_pronostico = ['congestion','x','y','bearing_t','speed_t','lag1', 'lag2', 'lag3','hora','minuto','isFuture']\n",
    "df_and_future = df_and_future[variables_pronostico]\n",
    "df_and_future.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2545ad95-2e01-4677-8a9e-16d0d8966944",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_and_future.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99c2e9c7-b3f4-4791-abad-7b83b9473726",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    #Create time series features based on time series index\n",
    "    df = df.copy()\n",
    "    df['hora'] = df.index.hour\n",
    "    df['minuto'] = df.index.minute\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33d7b4a2-6d44-48d0-be7c-e2a08b8f595a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_cong_balanceado.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c3c783c-8956-408d-a1bd-5e3c5dab20b8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_and_future.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6b9a9b6-504c-4c57-8986-19d6733c1205",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_and_future.index.max() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "608d6332-2742-4397-a04f-2f67e89395d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#‘W’, or ‘D’\n",
    "#‘days’, or ‘day’\n",
    "#‘hours’, ‘hour’, ‘hr’, or ‘h’\n",
    "#‘minutes’, ‘minute’, ‘min’, or ‘m’\n",
    "#‘seconds’, ‘second’, ‘sec’, or ‘s’\n",
    "def add_lags(df):\n",
    "    #Hacemos un diccionario con los valores del TARGET, para completar luego\n",
    "    target_map = df['congestion'].to_dict()\n",
    "\n",
    "    #datos_cong_balanceado['lag1'] = (datos_cong_balanceado.index - pd.Timedelta('1 days')).map(target_map)  #Retroceso 1, en este caso (1 dia)\n",
    "    #df['lag1'] = (df.index - pd.Timedelta('5T')).map(target_map)  #Retroceso 1, en este caso (5 minutos)\n",
    "    df['lag1'] = (df.index - pd.Timedelta(25, 'hours')).map(target_map)  #Retroceso 1, en este caso (1 dia)\n",
    "    df['lag2'] = (df.index - pd.Timedelta(32, 'hours')).map(target_map)  #Retroceso 2, en este caso (2 dia)\n",
    "    df['lag3'] = (df.index - pd.Timedelta(40, 'hours')).map(target_map)  #Retroceso 3, en este caso (3 dia)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e888659-c601-4b21-b20d-03aca4b48001",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_and_future = create_features(df_and_future)\n",
    "df_and_future = add_lags(df_and_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "857a679c-4093-4b28-b63d-b1c511a82c4a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_and_future.tail(310)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdbeb750-eb88-4f7e-948b-8b3d9476a374",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_and_future.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d954b210-79d3-4b6d-9bc3-e02c44c5bcb7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Filtramos solo el Dataset Esqueleto para el Pronostico\n",
    "future_dates_pronostico = df_and_future.query('isFuture').copy()\n",
    "future_dates_pronostico.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74087bd2-99ea-48ce-9a9e-430642449d2c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_and_future['x'].loc[future - pd.Timedelta(days=1)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da9b0cd2-c685-4148-8388-8b4aab781237",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# datos_cong_balanceado[['x','y','bearing_t','speed_t']].tail(288)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "659c1c36-7bbf-4faa-bbeb-94eb6e6b4d88",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Identificamos las columnas a completar usando los datos del día anterior\n",
    "columns_to_fill = ['x', 'y', 'bearing_t', 'speed_t']\n",
    "\n",
    "# Rellenamos las columnas específicas con los valores del día anterior\n",
    "for col in columns_to_fill:\n",
    "    future_dates_pronostico[col] = df_and_future[col].loc[future - pd.Timedelta(days=1)].values\n",
    "\n",
    "# Las otras columnas se quedan con NaN o el valor que tenías en el DataFrame de predicción\n",
    "future_dates_pronostico.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dcc23c69-0f53-4429-8fc9-54cf785edd02",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Predict the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "647595a2-0891-434e-a211-c5f63f619bf1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "FEATURES = ['x','y','bearing_t','speed_t','lag1', 'lag2', 'lag3','hora','minuto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2139c2de-dc7c-4955-94e2-615ae7536922",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89cdc909-4245-491d-814b-1f7a6ff9446c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "column_pred_congestion = xgb_model.predict_proba(future_dates_pronostico[FEATURES])\n",
    "column_pred_congestion = column_pred_congestion[:, 1]\n",
    "future_dates_pronostico['congestion_pred']=column_pred_congestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a848f641-7aed-4d3f-bee4-3ae50de577ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "future_dates_pronostico.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "853a4844-2355-45b3-b29f-80c5b1d5bbc3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "future_dates_pronostico['congestion_pred'].plot(figsize=(10,5),\n",
    "                                                ms=1,lw=1, title='Future Prediction Congestion 24-4-2024')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d6d0075-dab5-424b-8a5d-04011f9aca34",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Saving Model ML Time Series XGB for Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a4f0aad-8cb4-4233-b0f4-6cf0ce7a14bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "xgb_model.save_model('model_xgb_timeseries.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ebb3d03-19f7-491b-bf71-94d25889a0e2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Cargar el Modelo XGB Time Series para predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aaf7a946-90f5-45d3-b46e-e510470c1e58",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "model_xgb_new = xgb.XGBClassifier()\n",
    "model_xgb_new.load_model('model_xgb_timeseries.json')\n",
    "\n",
    "column_pred_congestion2 = model_xgb_new.predict_proba(future_dates_pronostico[FEATURES])\n",
    "column_pred_congestion2 = column_pred_congestion2[:, 1]\n",
    "future_dates_pronostico['congestion_pred_2']=column_pred_congestion2\n",
    "\n",
    "future_dates_pronostico['congestion_pred_2'].plot(figsize=(10,5),\n",
    "                                                ms=1,lw=1, title='Future Prediction Congestion 24-4-2024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9b2c3e2-71d1-4c99-8c92-6cbd9fc45a82",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "mask=future_dates_pronostico['x']>0 \n",
    "data=future_dates_pronostico[mask]\n",
    "sns.scatterplot(data['x'],data['y'], hue=data['congestion_pred_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46b337b6-3457-469f-9b0a-2c19b129798b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Algoritmo LSTM para Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb35ca16-4b60-4842-85fc-ba113158c7be",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9f64435-16d5-461d-9b41-e2e1c8c4c28a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#1. Leemos los datos de PROCEESED la tabla Delta \n",
    "df_delta2 = spark.read.format(\"delta\").load(\"/mnt/datalakemlopsd4m/presentation/proyectocongestion_presentation/data_congestion_serietemp_balanceada\")\n",
    "datos_cong_balanceado = df_delta2.toPandas()\n",
    "datos_cong_balanceado.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70562673-7e2a-43c8-980a-c52398eafbe1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Ajuste de los datos para problemas de Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a0c2929-1f50-4536-ba69-03fb5c18b806",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# #2. Ajuste de los datos a Series Temporales\n",
    "# #2.1 Se establece la columna 'Time' como el índice del DataFrame \"datos\"\n",
    "datos_cong_balanceado = datos_cong_balanceado.set_index('instant_date_t')\n",
    "\n",
    "# #2.3 Ordenamos el dataset de forma ascendente segun el datetime\n",
    "datos_cong_balanceado.sort_index(inplace=True)\n",
    "\n",
    "#2.4 Identificamos la periocidad de la serie temporal\n",
    "df_time_diffs = datos_cong_balanceado.index.to_series().diff().dt.total_seconds()\n",
    "\n",
    "# # 2.4.1 Contar cuántas diferencias de tiempo tienen cada valor específico\n",
    "# diferencias_frecuencias = df_time_diffs.value_counts().sort_index()\n",
    "# # 2.4.2 Mostrar los recuentos\n",
    "# print(diferencias_frecuencias)\n",
    "\n",
    "#3. Eliminamos o Filtramos las filas donde la diferencia es distinta de cero (Con ello eliminamos las filas o registros de fechas duplicadas)\n",
    "datos_cong_balanceado = datos_cong_balanceado[df_time_diffs != 0]\n",
    "\n",
    "#4. # Reinterpolar el dataset con una periosidad en especifico\n",
    "# 'S' o 'seg' : Segundo, 'T' o 'min': Minuto,'H' o 'Hr': Hora,'D': Día,'W': Semana,'M': Mes,'Q': Trimestre,'Y': Año\n",
    "datos_cong_balanceado = datos_cong_balanceado.asfreq(freq='6s', method='bfill')\n",
    "\n",
    "# Filtramos los valores de x, y, z que son 0s\n",
    "mask = (datos_cong_balanceado['x'] == 0) & (datos_cong_balanceado['y'] == 0) & (datos_cong_balanceado['z'] == 0)\n",
    "datos_cong_balanceado = datos_cong_balanceado[~mask]\n",
    "\n",
    "datos_cong_balanceado.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9dc3d30-617a-4577-bb4a-9ff0473817e7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Definir si sera Modelo Univariado o Multivariado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ff632e5-ff67-48bd-804c-0751c1ae0a62",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#datos_df = datos_cong_balanceado['congestion']  # Modelo Univariado\n",
    "datos_df = datos_cong_balanceado[['x','speed_t','congestion']]  # Modelo Multivariado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9863d6d3-700f-43a3-91e0-f51a328c3f7f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Escalar/Normalizar los datos \n",
    "Es requerido para garantizar que todas las caracteristicas se encuentren en el mismo rango\n",
    "de valores, lo que facilita el entrenamiento del Modelo y las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2792ac9c-0b89-4624-870a-959a8fcea785",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def escalar_por_variables_especificas(dataframe, variables_a_escalar, medias, desviaciones_estandar):\n",
    "  \"\"\"\n",
    "  Escala solo las variables especificadas en un dataframe de forma independiente.\n",
    "\n",
    "  Args:\n",
    "    dataframe: El dataframe que se va a escalar.\n",
    "    variables_a_escalar: Una lista que contiene los nombres de las variables que se van a escalar.\n",
    "    medias: Un diccionario que contiene la media de cada variable.\n",
    "    desviaciones_estandar: Un diccionario que contiene la desviación estándar de cada variable.\n",
    "\n",
    "  Returns:\n",
    "    El dataframe escalado.\n",
    "  \"\"\"\n",
    "  dataframe_escalado = dataframe.copy()\n",
    "  for columna in dataframe.columns:\n",
    "    if columna in variables_a_escalar:\n",
    "      dataframe_escalado[columna] = (dataframe[columna] - medias[columna]) / desviaciones_estandar[columna]\n",
    "  return dataframe_escalado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb0098e6-adca-4bc0-9624-1f768f390e06",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Definir la lista de variables a escalar\n",
    "variables_a_escalar = [\"x\", \"speed_t\"]  # Reemplazar con los nombres reales de las columnas\n",
    "\n",
    "# Calcular medias y desviaciones estándar para todas las variables\n",
    "medias = datos_df.mean()\n",
    "desviaciones_estandar = datos_df.std()\n",
    "\n",
    "# Escalar solo las variables especificadas en el dataframe train\n",
    "df_escalado = escalar_por_variables_especificas(datos_df, variables_a_escalar, medias, desviaciones_estandar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5048060a-14e3-4721-ba1c-3ded34287a95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_escalado.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "827d71cc-bea2-4f22-b73a-5fca1b623bdd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Metodo de Desviacion estandar y MEDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "137fcdd1-ae29-4ad2-8f44-1c3408808df3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# train_mean = tr.mean() # Guardar este valor para usarlo cuando despliegues el Modelo en Produccion\n",
    "# train_std = tr.std()  # Guardar este valor para usarlo cuando despliegues el Modelo en Produccion \n",
    "\n",
    "# tr = (tr - train_mean) / train_std\n",
    "# vl = (vl - train_mean) / train_std\n",
    "# ts = (ts - train_mean) / train_std\n",
    "\n",
    "\n",
    "# INVERSION DE ESCALAMIENTO (CUANDO DESPLIEGUES EN PRODUCCION)\n",
    "# def invertir_escalamiento(predicciones, train_mean, train_std):\n",
    "#     return predicciones * train_std + train_mean\n",
    "\n",
    "# # Suponiendo que 'predicciones' son las predicciones de tu modelo\n",
    "# predicciones_invertidas = invertir_escalamiento(predicciones, train_mean, train_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c26c26b5-6846-4e47-ab58-1361ecc15264",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Metodo de Min Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "884f0baa-4fdd-4a65-b4c4-a9482158041f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ESCALAMIENTO\n",
    "# train_min = tr.min()   # Guardar este valor para usarlo cuando despliegues el Modelo en Produccion\n",
    "# train_max = tr.max()   # Guardar este valor para usarlo cuando despliegues el Modelo en Produccion\n",
    "\n",
    "# tr = (tr - train_min) / (train_max - train_min)\n",
    "# vl = (vl - train_min) / (train_max - train_min)\n",
    "# ts = (ts - train_min) / (train_max - train_min)\n",
    "\n",
    "# INVERSION DE ESCALAMIENTO (CUANDO DESPLIEGUES EN PRODUCCION)\n",
    "# def invertir_minmax_escalamiento(predicciones, train_min, train_max):\n",
    "#     return predicciones * (train_max - train_min) + train_min\n",
    "\n",
    "# # Suponiendo que 'predicciones' son las predicciones de tu modelo\n",
    "# predicciones_invertidas = invertir_minmax_escalamiento(predicciones, train_min, train_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1db932cd-acaa-45fe-91f6-9e50969b852e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "5.1 Particion del Set en entrenamiento, validacion y prueba\n",
    "- En el caso de series temporales se debe garantizar que se generan las particiones sin mezclar aleaotariamente\n",
    "\n",
    "Recordemos\n",
    "\n",
    ". El set entrenamiento se usa para encontrar los parametros \n",
    "\n",
    ". El set validacion para verificar que no haya under/over fitting\n",
    "\n",
    ". El set de prueba para poner a prueba el mejor modelo encontrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad72d3a3-d1b9-4043-8233-c1eabad94ec7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Funcion para generar las particiones, siguiendo la secuencia de las series temporales\n",
    "def train_val_test_split(serie, tr_size =0.8, vl_size=0.1, ts_size=0.1):\n",
    "    # Definir nunmero de datos en cada subserie\n",
    "    N = serie.shape[0]   #Serie seria el df, con las columnas que intervendran en el Modelo\n",
    "    Ntrain = int(tr_size*N)  # Numero de datos de entrenamiento\n",
    "    Nval = int(vl_size*N)\n",
    "    Ntest = int(ts_size*N)\n",
    "\n",
    "    #Realizar la particion\n",
    "    train = serie[0:Ntrain]\n",
    "    val = serie[Ntrain:Nval+Ntrain]\n",
    "    test = serie[Nval+Ntrain:]\n",
    "\n",
    "    return train, val, test\n",
    "\n",
    "\n",
    "# Prueba de la funcion \n",
    "tr, vl, ts  = train_val_test_split(datos_df)\n",
    "\n",
    "print(f'Shape del Set de Entrenamiento, {tr.shape}')\n",
    "print(f'Shape del Set de Validacion, {vl.shape}')\n",
    "print(f'Shape del Set de Test, {ts.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67353077-db26-4ee7-94fc-9280c81c0829",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20b43b28-3419-43fd-815e-2028657187f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#datos_cong_balanceado.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e32b99a-4028-4da8-9e53-2587461b152f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#Dibujemos los subsets\n",
    "fig, ax  = plt.subplots(figsize  = (15,5))\n",
    "ax.plot(tr, label = 'Train')\n",
    "ax.plot(vl, label = 'Validation')\n",
    "ax.plot(ts, label = 'Test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "644b4344-4ef1-4766-984b-9841efa1355e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Grafico de Cada Serie Temporal (Analisis Multivariado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb4dd77f-1a70-4e9d-adfd-253ac801bc37",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "covar  = 1# Indice de la covariable (columna del dataset) a graficar\n",
    "col  = datos_df.columns[covar]\n",
    "\n",
    "# Dibujar los sets de entrenamiento, validacion, prueba\n",
    "fig, ax = plt.subplots(figsize=(16,5))\n",
    "ax.plot(tr[col], label='Train')\n",
    "ax.plot(vl[col], label='Validation')\n",
    "ax.plot(ts[col], label='Test')\n",
    "ax.set_title(f'Variable, {col}')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d1c0f34-a37a-4030-80f0-1005fddf3121",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###5.2 Generación del dataset supervisado (entrada y salida del modelo)\n",
    "\n",
    "Debemos ajustar nuestro set de datos de acuerdo a lo especificado en la documentacion de LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "335dcc41-048e-490f-861d-5f1e8ed6f8d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# Asegúrate de que la ruta de la imagen sea correcta\n",
    "img_path = 'entradas_salidas_LSTM.png'\n",
    "\n",
    "# Muestra la imagen\n",
    "Image(filename=img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c613fcf-9b0b-4dae-b669-65a305ba6921",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# Asegúrate de que la ruta de la imagen sea correcta\n",
    "img_path = 'lstm_multivariado.png'\n",
    "\n",
    "# Muestra la imagen\n",
    "Image(filename=img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9fe0365f-d02c-4b9a-af33-42d66522486f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Así que en este caso cada dato de entrenamiento será:\n",
    "\n",
    "- Un arreglo de 24 (horas) x 1 (feature) correspondiente a la entrada\n",
    "- Un arreglo de 1 (hora) x 1 (feature) correspondiente a la hora 25 (a predecir):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a026a55a-c7c6-48dd-89b4-726a845e9e23",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# Asegúrate de que la ruta de la imagen sea correcta\n",
    "img_path = 'dataset_supervisado.png'\n",
    "\n",
    "# Muestra la imagen\n",
    "Image(filename=img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ede2216c-9e03-4867-883c-98b2935e5f20",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Creamos la funcion que pondremos reutilizar mas adelante para implementar modelos mas complejos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4667a4d3-f112-402f-b76d-308326400365",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def crear_dataset_supervisado(array, input_length, output_length): \n",
    "    ''' Permite crear un dataset con las entradas (X) y salidas (Y)\n",
    "    requeridas por las Red LSTM.\n",
    "\n",
    "    Parametros :\n",
    "    - array : arreglo numpy de tamano N * Features (N: cantidad de datos, Features: Cantidad de features)\n",
    "    -  input_length : Instantes de tiempo consecutivos de la(s) serie(s) de tiempo usados para alimentar al modelo (bloques de bash para ingresar ala LSTM)\n",
    "    -  output_length : instantes de tiempo a pronosticar (salida del modelo)\n",
    "    '''\n",
    "    #Inizializacion\n",
    "    X, Y = [], []   #Listados que contendran los datos de entrada y salida del modelo (Lotes o Batches)\n",
    "    shape = array.shape\n",
    "    if len(shape) == 1:  #Si tenemos solo una variable(serie) UNIVARIADO\n",
    "        fils, cols = array.shape[0], 1   #UNIVARIADO (Por ello solo 1 columna)\n",
    "        array = array.reshape(fils,cols)\n",
    "    else: #MULTIVARIDAO\n",
    "        fils, cols = array.shape\n",
    "\n",
    "    #Generar los arreglos\n",
    "    for i in range(fils-input_length-output_length):\n",
    "        X.append(array[i:i+INPUT_LENGTH,0:cols])\n",
    "        Y.append(array[i+input_length:i+input_length+output_length,-1].reshape(output_length,1))\n",
    "    \n",
    "    #Convertir listas a arreglos Numpy\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d02c506-4a3c-4f52-9d29-c86f0c386259",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Crear los datasets de entrenamiento, validacion, prueba\n",
    "INPUT_LENGTH = 2 # Numero de Pasos en el pasado\n",
    "OUTPUT_LENGTH = 1  # Modelo Uni Step (1 en este casoi indica 1 fila adelante), Multistep mas de 1 \n",
    "\n",
    "x_tr, y_tr = crear_dataset_supervisado(tr.values, INPUT_LENGTH, OUTPUT_LENGTH)\n",
    "x_vl, y_vl = crear_dataset_supervisado(vl.values, INPUT_LENGTH, OUTPUT_LENGTH)\n",
    "x_ts, y_ts = crear_dataset_supervisado(ts.values, INPUT_LENGTH, OUTPUT_LENGTH)\n",
    "\n",
    "#Imprimimos la informacion en pantalla\n",
    "print('Tamanos entrada (BATCHES x INPUT_LENGTH x FEATURES) y de salida (BACTHES x OUTPUT_LENGTH x FEATURES)')\n",
    "\n",
    "print(f'Set de entenamiento x_tr : {x_tr.shape}, y_tr : {y_tr.shape}')\n",
    "print(f'Set de validacion x_vl : {x_vl.shape}, y_vl : {y_vl.shape}')\n",
    "print(f'Set de entenamiento x_ts : {x_ts.shape}, y_ts : {y_ts.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a36d10f-ae6a-4d3c-8a0c-67c1844bc3a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tr.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c30e91b7-5200-411f-84f3-5b450664a96a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "x_tr[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8b587d3-63ea-4730-ac21-a5e3ebc89d85",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d521308-b66a-442b-9587-7aef3590fecc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Construccion y Entrenamiento del Modelo\n",
    "- Entradas : arreglos x (batches x input_length x features = batches x 24 x 1)\n",
    "- Salidas : arreglos y (batches x output_length x features = batches x 1 x 1)\n",
    "\n",
    "Usaremos la RSME para medir el performance del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42f57bf9-601c-4a69-a712-cdebf2195ec7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "x_tr.shape[1], x_tr.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5309fe62-152c-4a4b-89e7-b7d847822fd7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Construccion del Modelo\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "# Fijar Valores parametros , para asegurar la reproducibilidad de los datos inicializados\n",
    "tf.random.set_seed(123) # Semilla(inicializacion de los parametros o pesos de misma manera)\n",
    "tf.config.experimental.enable_op_determinism() # Cada vez se ejecute de misma manera\n",
    "\n",
    "# El Modelo\n",
    "N_UNITS = 150 # Tamaño del estado oculto de la celda de Memoria de LSTM\n",
    "INPUT_SHAPE = (x_tr.shape[1], x_tr.shape[2]) #50 pasos atras x n features (feature)\n",
    "\n",
    "modelo = Sequential()\n",
    "modelo.add(LSTM(N_UNITS, input_shape=INPUT_SHAPE))\n",
    "modelo.add(Dense(OUTPUT_LENGTH, activation='sigmoid')) # linear: problema regresion, sigmoid:clasificacion binaria, softmax:multiclase\n",
    "\n",
    "#RSME: Para problemas de regresion, para tener errores en las mismas unidades de la variable target\n",
    "# def root_mean_squared_error(y_true,y_pred):\n",
    "#     rmse=tf.math.sqtr(tf.math.reduce_mean(tf.square(y_pred-y_true)))\n",
    "#     return rmse\n",
    "\n",
    "# Optimizador para problema de regresion\n",
    "# optimizador = RMSprop(learning_rate=0.05)\n",
    "\n",
    "#Compilation\n",
    "\n",
    "\n",
    "# Compilar el modelo\n",
    "modelo.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy','AUC'])\n",
    "\n",
    "# Entrenamiento del Modelo\n",
    "EPOCHS = 50 # Numero de epocas de entrenamiento\n",
    "BATCH_SIZE = 256 # Numero de lotes que van ingresando al Modelo(Algoritmo)\n",
    "historia = modelo.fit(\n",
    "    x = x_tr,\n",
    "    y = y_tr,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    epochs = EPOCHS,\n",
    "    validation_data = (x_vl, y_vl),\n",
    "    verbose=2  #Imprime en pantalla con va el entrenamiento\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee0c036d-0b31-401c-ba30-60bbeb423a0b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Graficar curvas de entrenamiento y validacion, para verificar que no existe overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6a6f252-262b-4ad4-9745-cdd8eba5231c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(historia.history['loss'],label='Loss Train')\n",
    "plt.plot(historia.history['val_loss'],label='Loss Validation')\n",
    "plt.xlabel('Iteracion')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77ce9c00-029d-4b9a-8a3f-166389b55238",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(historia.history['accuracy'],label='Accuracy Train')\n",
    "plt.plot(historia.history['val_accuracy'],label='Accuracy Validation')\n",
    "plt.xlabel('Iteracion')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df9f99c4-d763-47c6-b59e-5042d1984f1b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 7.Performance del Modelo\n",
    "Verificamos el rendimiento para el set de test , y comparamos con el de \n",
    "entrenamiento y validacion.\n",
    "Este rendimiento es simplemente el LOSS obtenido con cada subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04048569-1958-4782-978d-a2dfacc8c4ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculo de Loss Binary para train, val, test\n",
    "loss_tr = modelo.evaluate(x=x_tr, y=y_tr, verbose=0) #verbose=0 No se imprime el progreso\n",
    "loss_vl = modelo.evaluate(x=x_vl, y=y_vl, verbose=0) #No se imprime el progreso\n",
    "loss_ts = modelo.evaluate(x=x_ts, y=y_ts, verbose=0) #No se imprime el progreso\n",
    "\n",
    "# Los valores de pérdida son los primeros elementos de las listas devueltas por evaluate()\n",
    "loss_tr_value = loss_tr[0]\n",
    "loss_vl_value = loss_vl[0]\n",
    "loss_ts_value = loss_ts[0]\n",
    "\n",
    "# Imprimir resultados en pantalla\n",
    "print('Comparativo rendimiento:')\n",
    "print(f'Loss train {loss_tr_value:.3f}')\n",
    "print(f'Loss val {loss_vl_value:.3f}')\n",
    "print(f'Loss test {loss_ts_value:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "964fbaf0-11bd-42a7-89bd-1eefcf4f4493",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 8. Predicciones en el Datos de Test con el Modelo Entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2dbd5d0-32bc-4cc2-9e8c-d9cc9edbb0fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def predecir(x, model):\n",
    "    '''Genera la prediccion OUTPUT_LENGTH de tiempo a futuro con el modelo entrenado\n",
    "    Entrada: \n",
    "    X: batch de datos para ingresar al modelo\n",
    "    model: Red LSTM\n",
    "\n",
    "    Salida:\n",
    "    y_pred:prediccion en la escala original (tamano de Bacthes)\n",
    "    '''\n",
    "    y_pred = modelo.predict(x,verbose=0)\n",
    "\n",
    "    # Llevar la prediccion a la escala original\n",
    "    # train_std=0\n",
    "    # train_mean=0\n",
    "    # y_pred_inversa = y_pred * train_std + train_mean\n",
    "\n",
    "    return y_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4878ef4-a1ad-491f-9c7c-46d080d44142",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calcular prediciones sobre el datos de TEST\n",
    "y_ts_pred = predecir(x_ts, modelo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10660efb-faed-49b5-98a9-0b23c7ad81eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "x_ts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e6ad906-a287-495e-9365-87f669624433",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "len(y_ts_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "841e1cbc-7726-4be6-9ca0-90cf8262f7b1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Opcional : En caso sea problema de Regresion , se puede tambien graficar la grafica de errores del Modelo, osea en cuantas unidades se equivoco el #modelo al momento de predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4cc0e63f-7593-44aa-9760-5f9fc9884955",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## En caso sea problema de Regresion , se puede tambien graficar la grafica de errores del Modelo, osea en cuantas unidades se equivoco el #modelo al momento de predecir\n",
    "N = len(y_ts)\n",
    "ndato=np.linspace(1,N,N)\n",
    "\n",
    "#Calculo de errores simples\n",
    "errores = y_ts.flatten()-y_ts_pred\n",
    "plt.plot(errores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72654132-b149-4d40-a8ce-d706f83a67c9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Pronostico al Futuro usando la Red LSTM entrenada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f67d222-1417-4a41-ac5b-15c5bdbb74c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_cong_balanceado.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ed53966-6993-4fc2-8c0c-6254f9df5948",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#future=pd.date_range(datos_cong_balanceado.index.max() + pd.Timedelta(minutes=5), datos_cong_balanceado.index.max() + pd.Timedelta(days=1) , #freq='5T')\n",
    "datos_cong_balanceado[\"congestion\"][datos_cong_balanceado.index.max() - pd.Timedelta(days=1) :datos_cong_balanceado.index.max()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afc07b1b-e0e6-4e8b-a9dc-d304a5332df2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Seleccionamos los datos del Ultimo dia de datos, para hacer la prediccion al futuro usando el Modelo Entrenado LSTM(fue entrenado con 50 #pasos atras)\n",
    "ultimosDias = datos_cong_balanceado[\"congestion\"][datos_cong_balanceado.index.max() - pd.Timedelta(days=1) :datos_cong_balanceado.index.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f437ae3-7eed-433e-ab7d-075f1c4d3a1f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ultimosDias.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bec30a75-2bab-4c25-8513-812189250dcf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Filtrar solo la ultima fila del array, lo que representaria los ultimas fechas del dataset\n",
    "reframed.values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64fe8c4d-fb4b-4570-9545-29b05ba5325c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#De este conjunto “ultimosDias” tomamos sólo la última fila, pues es la que correspondería a la última semana de noviembre y la dejamos en el #formato correcto para la red neuronal con reshape:\n",
    "values = reframed.values\n",
    "x_test = reframed.values[-1]\n",
    "x_test = x_test.reshape((x_test.shape[0], 1))\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "091087ab-f6b8-4cf0-bc68-18c8ac8e858a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "x_ts[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "164630d4-ffcf-4874-86e7-24a6656c6a67",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33e197bc-981d-4895-9348-362a82aebfbf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Ahora crearemos una función para ir “rellenando” el desplazamiento que hacemos por cada predicción. Esto es porque queremos predecir los pasos adelante (en este caso 1 dia siguiente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ceb335f-ce20-4d83-951f-0f4519718181",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Función para actualizar la secuencia con el nuevo valor predicho\n",
    "def actualizarSecuencia(x_test, nuevo_valor):\n",
    "    # Desplazar los valores a la izquierda\n",
    "    for i in range(x_test.shape[0] - 1):\n",
    "        x_test[i] = x_test[i + 1]\n",
    "    # Añadir el nuevo valor predicho al final de la secuencia\n",
    "    x_test[-1] = nuevo_valor\n",
    "    return x_test\n",
    "\n",
    "def agregarNuevoValor(x_test,nuevoValor):\n",
    "    for i in range(x_test.shape[2]-1):\n",
    "        x_test[0][0][i] = x_test[0][0][i+1]\n",
    "    x_test[0][0][x_test.shape[2]-1]=nuevoValor\n",
    "    return x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66b924cd-80ce-4b84-8bf6-d215ef16a420",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a3d6b9d-d9cf-47a2-94f4-17068bc0c447",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "modelo.predict(x_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cae3dec-7492-4443-8d53-132d092541a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Número de pasos hacia el futuro que quieres predecir\n",
    "n_steps = 150\n",
    "\n",
    "# Lista para almacenar los resultados de las predicciones\n",
    "resultados = []\n",
    "\n",
    "# Bucle para hacer las predicciones\n",
    "for _ in range(n_steps):\n",
    "    # Hacer una predicción sobre la secuencia actual de x_test\n",
    "    prediccion = modelo.predict(x_test)\n",
    "    # Almacenar la predicción\n",
    "    resultados.append(prediccion[0])\n",
    "    # Actualizar la secuencia de entrada con el nuevo valor predicho\n",
    "    x_test = actualizarSecuencia(x_test, prediccion[0])\n",
    "\n",
    "# Mostrar los resultados de las predicciones\n",
    "print(\"Predicciones futuras:\", resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21abaf34-73e3-4c3d-b92b-74f2cf49ebf0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "adimen = [x for x in resultados]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "705e52b3-da9c-4ed2-83bc-02c28d2d613c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "adimen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7481f7a8-adbe-4093-b267-549bb714941d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prediccion_24abril = pd.DataFrame(adimen)\n",
    "prediccion_24abril.columns = ['pronostico']\n",
    "prediccion_24abril.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8bb30013-7981-4989-8fe9-911c07aa7f23",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##  Time Series how Problem de Aprendizaje supervisado "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db69c23c-43e9-4940-9696-7d636c5e26e0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "1. Ejemplo de explicacion como podriamos pasar de problema de serie temporal a aprendizaje supervisado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8834826b-ab73-440b-a7d0-7f8fa0c2b8f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "df = DataFrame()\n",
    "df['t'] = [x for x in range(10)]\n",
    "df['t-1'] = df['t'].shift(1)  # 1 un paso atras, =1 un paso adelante\n",
    "df['t-2'] = df['t'].shift(2)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6658af2-4d51-4792-a69f-3d950892df1a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "values = [x for x in range(10)]\n",
    "data = series_to_supervised(values, 3)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86fc1e47-4791-4bce-a3b1-bce5c1d2603f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "raw = DataFrame()\n",
    "raw['ob1'] = [x for x in range(10)]\n",
    "raw['ob2'] = [x for x in range(50, 60)]\n",
    "values = raw.values\n",
    "values\n",
    "#data = series_to_supervised(values)\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e08aacf-69fd-439c-85a4-cce8048f9372",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = series_to_supervised(values)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3fe64f4-c6bb-4b3a-b39d-b68409322927",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Cargamos los datos a Analizar y pasar de Time Series a Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4119abc6-c15b-4336-aac3-fab28d79ffe1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#1. Leemos los datos de PROCEESED la tabla Delta \n",
    "# df_delta2 = spark.read.format(\"delta\").load(\"/mnt/datalakemlopsd4m/presentation/proyectocongestion_presentation/tablacaracteristicas_congestion_tabladelta_v3\")\n",
    "\n",
    "df_delta2 = spark.read.format(\"delta\").load(\"/mnt/datalakemlopsd4m/presentation/proyectocongestion_presentation/data_congestion_serietemp_balanceada\")\n",
    "\n",
    "datos_cong_balanceado = df_delta2.toPandas()\n",
    "datos_cong_balanceado.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b95da3a-5324-4353-a8ed-9f518af042bb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Ajuste de los datos para problemas de Time Series(Establecer la Frecuencia )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d979811-222c-4079-a603-02dcfb025578",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# #2. Ajuste de los datos a Series Temporales\n",
    "# #2.1 Se establece la columna 'Time' como el índice del DataFrame \"datos\"\n",
    "datos_cong_balanceado = datos_cong_balanceado.set_index('instant_date_t')\n",
    "\n",
    "# #2.3 Ordenamos el dataset de forma ascendente segun el datetime\n",
    "datos_cong_balanceado.sort_index(inplace=True)\n",
    "\n",
    "#2.4 Identificamos la periocidad de la serie temporal\n",
    "df_time_diffs = datos_cong_balanceado.index.to_series().diff().dt.total_seconds()\n",
    "\n",
    "# # 2.4.1 Contar cuántas diferencias de tiempo tienen cada valor específico\n",
    "# diferencias_frecuencias = df_time_diffs.value_counts().sort_index()\n",
    "# # 2.4.2 Mostrar los recuentos\n",
    "# print(diferencias_frecuencias)\n",
    "\n",
    "#3. Eliminamos o Filtramos las filas donde la diferencia es distinta de cero (Con ello eliminamos las filas o registros de fechas duplicadas)\n",
    "datos_cong_balanceado = datos_cong_balanceado[df_time_diffs != 0]\n",
    "\n",
    "#4. # Reinterpolar el dataset con una periosidad en especifico\n",
    "# 'S' o 'seg' : Segundo, 'T' o 'min': Minuto,'H' o 'Hr': Hora,'D': Día,'W': Semana,'M': Mes,'Q': Trimestre,'Y': Año\n",
    "#datos_cong_balanceado = datos_cong_balanceado.asfreq(freq='5T', method='bfill')\n",
    "datos_cong_balanceado = datos_cong_balanceado.asfreq(freq='6s', method='bfill')\n",
    "\n",
    "# Filtramos los valores de x, y, z que son 0s\n",
    "mask = (datos_cong_balanceado['x'] == 0) & (datos_cong_balanceado['y'] == 0) & (datos_cong_balanceado['z'] == 0)\n",
    "datos_cong_balanceado = datos_cong_balanceado[~mask]\n",
    "\n",
    "datos_cong_balanceado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8755dcd2-442a-47c5-9092-44820034ffe4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_cong_balanceado.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a3a59ef-aaca-48c1-9c52-aac4153c4a4d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_cong_balanceado['congestion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b98eb04c-2aed-4d23-8569-42410f0f2ff0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Va\n",
    "datos_cong_balanceado['congestion'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7987cd2e-25ce-4bf3-8904-fd4fa8b384ff",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Eleccion de si es Modelo Univariado o Multivariado (Poner la columna a Predecir en la ultima columna )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc137cc7-190d-4aad-9db9-e5de416ef916",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#datos_df = datos_cong_balanceado['congestion']  # Modelo Univariado\n",
    "\n",
    "\n",
    "#En Multivariado, poner la variable a predecir, en la columna final\n",
    "# c_variables = ['id_equipo','id_worker','id_path','n_sat','isload_t','marcha_t','precisiongps_t','x','y','z','direccion_t'\n",
    "# ,'speed_t','pitch_t','roll_t','segment_angle_t','tonelaje_t','fuel_rate_t','combustibleint_t'\n",
    "# ,'LCKUP_SLIP','BRK/AIR_PRES','RTF_LTF_BRKTEMP','RTR_LTR_BRKTEMP','RT_F_BRK_TEMP','RT_R_BRK_TEMP','LT_R_BRK_TEMP','SERV_BRK_STAT','Tire_Press_N4','Tire_Press_N6','Hourmeter_MSPU','Direction','congestion']\n",
    "\n",
    "c_variables = ['x','speed_t','congestion']\n",
    "\n",
    "\n",
    "datos_df = datos_cong_balanceado[c_variables]  # Modelo Multivariado\n",
    "datos_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b0c12a4-600f-42de-a12b-4934318f50dd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Escalar/Normalizar los datos \n",
    "- Es requerido para garantizar que todas las caracteristicas se encuentren en el mismo rango\n",
    "de valores, lo que facilita el entrenamiento del Modelo y las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0904e0e7-ea72-42c1-b340-667361d606fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def escalar_por_variables_especificas(dataframe, variables_a_escalar, medias, desviaciones_estandar):\n",
    "  \"\"\"\n",
    "  Escala solo las variables especificadas en un dataframe de forma independiente.\n",
    "\n",
    "  Args:\n",
    "    dataframe: El dataframe que se va a escalar.\n",
    "    variables_a_escalar: Una lista que contiene los nombres de las variables que se van a escalar.\n",
    "    medias: Un diccionario que contiene la media de cada variable.\n",
    "    desviaciones_estandar: Un diccionario que contiene la desviación estándar de cada variable.\n",
    "\n",
    "  Returns:\n",
    "    El dataframe escalado.\n",
    "  \"\"\"\n",
    "  dataframe_escalado = dataframe.copy()\n",
    "  for columna in dataframe.columns:\n",
    "    if columna in variables_a_escalar:\n",
    "      dataframe_escalado[columna] = (dataframe[columna] - medias[columna]) / desviaciones_estandar[columna]\n",
    "  return dataframe_escalado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd349717-dcff-4f58-8fd7-21964dc18ae4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Definir la lista de variables a escalar\n",
    "variables_a_escalar = [\"x\", \"speed_t\"]  # Reemplazar con los nombres reales de las columnas\n",
    "\n",
    "# Calcular medias y desviaciones estándar para todas las variables\n",
    "medias = datos_df.mean()\n",
    "desviaciones_estandar = datos_df.std()\n",
    "\n",
    "# Escalar solo las variables especificadas en el dataframe train\n",
    "df_escalado = escalar_por_variables_especificas(datos_df, variables_a_escalar, medias, desviaciones_estandar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b986ae22-6abf-4d89-b91e-d05de88d6f07",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Generacion del DataSet Supervisado\n",
    "- Función de Python llamada series_to_supervised()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08cf1ef4-6fb8-496e-9d5d-68853d1e6302",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Función de Python llamada series_to_supervised() que toma una serie temporal univariada o multivariada y la encuadra como un #conjunto de datos de aprendizaje supervisado.\n",
    "import pandas as pd\n",
    " \n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "    data: Secuencia de observaciones como una lista o matriz NumPy 2D.\n",
    "    n_in : número de observaciones de retraso como entrada ( X ). Los valores pueden estar entre [1..len(data)] Opcional. El valor predeterminado es 1.\n",
    "    n_out : Número de observaciones como salida ( y ). Los valores pueden estar entre [0..len(data)-1]. Opcional. El valor predeterminado es 1.\n",
    "    dropnan : valor booleano para eliminar o no filas con valores NaN. Opcional. El valor predeterminado es Verdadero.\n",
    "\n",
    "    Returns:\n",
    "    Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))    # Aplicas los pasos hacia atras \n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))   # Aplicas los pasos hacia adelante\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)    #Eliminamos las filas Nulas de nuestro df generado(Porque no sirven en la serie temporal)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4d75fd1-92aa-4414-88f8-1d3c1070e786",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Crear los datasets de entrenamiento, prueba y validación y verificar sus tamaños\n",
    "numero_pasos_atras = 1  # Hiperparámetro\n",
    "numero_pasos_futuro = 1   # Modelo uni-step igual a 1 paso,   MUltivariado seria mayor a 1 paso al futuro\n",
    "\n",
    "# tr_s = series_to_supervised(tr.values, numero_pasos_atras , numero_pasos_futuro)\n",
    "# vl_s = series_to_supervised(vl.values, numero_pasos_atras, numero_pasos_futuro)\n",
    "# ts_s = series_to_supervised(ts.values, numero_pasos_atras, numero_pasos_futuro)\n",
    "\n",
    "datos_df_s = series_to_supervised(datos_df.values, numero_pasos_atras, numero_pasos_futuro)\n",
    "\n",
    "# Asignar nombres originales a las columnas\n",
    "original_columns = datos_df.columns\n",
    "\n",
    "new_columns = []\n",
    "for i in range(numero_pasos_atras, 0, -1):\n",
    "    new_columns += [f'{col}(t-{i})' for col in original_columns]\n",
    "for i in range(0, numero_pasos_futuro):\n",
    "    if i == 0:\n",
    "        new_columns += [f'{col}(t)' for col in original_columns]\n",
    "    else:\n",
    "        new_columns += [f'{col}(t+{i})' for col in original_columns]\n",
    "\n",
    "datos_df_s.columns = new_columns\n",
    "datos_df_s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0edef4b-1596-4ef9-a9a9-fe7d1438709a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_df_s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddb0c301-3589-41c6-9a3f-4c513ba9f484",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Solo nos quedamos en la ultima columna con la columna a predecir (Las demas que estan en el tiempo T se eliminan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "931a0f86-db1d-4477-8636-4a3df50b5dca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Solo nos quedariamos con la variable congestion(t)  como target\n",
    "columns_to_drop = ['x(t)', 'speed_t(t)']\n",
    "datos_df_s.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "842944ca-2513-49e9-a933-f70fe47d0267",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_df_s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce393355-878c-4860-868f-a85c2ac6d903",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_df_s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69116038-18f4-42e3-b293-1b83b6cc87f1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Separamos los datos en Train, Validation, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab31e739-7c4b-474f-93ff-c9e35cd8d3ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Funcion para generar las particiones, siguiendo la secuencia de las series temporales\n",
    "def train_val_test_split(serie, tr_size =0.8, vl_size=0.1, ts_size=0.1):\n",
    "    # Definir nunmero de datos en cada subserie\n",
    "    N = serie.shape[0]   #Serie seria el df, con las columnas que intervendran en el Modelo\n",
    "    Ntrain = int(tr_size*N)  # Numero de datos de entrenamiento\n",
    "    Nval = int(vl_size*N)\n",
    "    Ntest = int(ts_size*N)\n",
    "\n",
    "    #Realizar la particion\n",
    "    train = serie[0:Ntrain]\n",
    "    val = serie[Ntrain:Nval+Ntrain]\n",
    "    test = serie[Nval+Ntrain:]\n",
    "\n",
    "    return train, val, test\n",
    "\n",
    "\n",
    "# Prueba de la funcion \n",
    "tr, vl, ts  = train_val_test_split(datos_df_s)\n",
    "\n",
    "print(f'Shape del Set de Entrenamiento, {tr.shape}')\n",
    "print(f'Shape del Set de Validacion, {vl.shape}')\n",
    "print(f'Shape del Set de Test, {ts.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32af3ca0-2f5b-4dcf-9536-3c5cabffc315",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Separamos las X(Variables predictoras) e Y(variable target), para luego poner en X_train, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f88c106-8f25-4bee-a652-7121e73c7d7b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def separar_X_y(df, target_col):\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "    return X, y\n",
    "\n",
    "# Separar características y objetivo para cada conjunto\n",
    "X_train, y_train = separar_X_y(tr, 'congestion(t)')\n",
    "X_val, y_val = separar_X_y(vl, 'congestion(t)')\n",
    "X_test, y_test = separar_X_y(ts, 'congestion(t)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d5b20b3-1213-4323-844e-678dbccf73fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datos_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a03e639-1b42-4c84-b266-c41ccba94e32",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c258704-c17d-4c60-ad2e-e363cd85a2da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed4e0b98-45c8-4e02-aeba-227aeb835664",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "La red LSTM espera que los datos de entrada (X) se proporcionen con una estructura de matriz específica en forma de: [muestras, pasos de tiempo, características]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2dd5db33-3455-43f9-8065-aaa147548a76",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n_features = X_train.shape[1]  # número de características predictoras\n",
    "# Función para reshape de X para LSTM\n",
    "def reshape_X_for_lstm(X, numero_pasos_atras, n_features):\n",
    "    n_samples = X.shape[0] - numero_pasos_atras - numero_pasos_futuro + 1\n",
    "    X_lstm = np.zeros((n_samples, numero_pasos_atras, n_features))\n",
    "    for i in range(n_samples):\n",
    "        X_lstm[i] = X.iloc[i:i+numero_pasos_atras, :].values\n",
    "    return X_lstm\n",
    "\n",
    "# Aplicar reshape para XS( X_train, X_val, X_test) para LSTM\n",
    "X_train_lstm = reshape_X_for_lstm(X_train, numero_pasos_atras, n_features)\n",
    "X_val_lstm = reshape_X_for_lstm(X_val, numero_pasos_atras, n_features)\n",
    "X_test_lstm = reshape_X_for_lstm(X_test, numero_pasos_atras, n_features)\n",
    "\n",
    "# Función para reshape para Ys () para LSTM\n",
    "def reshape_y_for_lstm(y, numero_pasos_futuro):\n",
    "    return y.iloc[numero_pasos_atras + numero_pasos_futuro - 1:].values.reshape(-1, numero_pasos_futuro, 1)\n",
    "\n",
    "# Aplicar reshape para y_train, y_val, y_test\n",
    "y_train_lstm = reshape_y_for_lstm(y_train, numero_pasos_futuro)\n",
    "y_val_lstm = reshape_y_for_lstm(y_val, numero_pasos_futuro)\n",
    "y_test_lstm = reshape_y_for_lstm(y_test, numero_pasos_futuro)\n",
    "\n",
    "# Verificar las formas después del reshape para LSTM\n",
    "print(\"Shape de X_train_lstm:\", X_train_lstm.shape)\n",
    "print(\"Shape de y_train_lstm:\", y_train_lstm.shape)\n",
    "print(\"Shape de X_val_lstm:\", X_val_lstm.shape)\n",
    "print(\"Shape de y_val_lstm:\", y_val_lstm.shape)\n",
    "print(\"Shape de X_test_lstm:\", X_test_lstm.shape)\n",
    "print(\"Shape de y_test_lstm:\", y_test_lstm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0f386e4-186e-4068-81e9-ca11e6585293",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train_lstm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f13cd0c-c066-4e1b-a978-5336441065b9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train_lstm[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c841114c-fc20-47d8-b1c5-6a90b5e4afd0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Metodos para pasar a formato de input para Redes Neuronales LSTM\n",
    "Ambos métodos pueden ser válidos dependiendo del contexto y la estructura de los datos.\n",
    "\n",
    "(282653, 2, 7), (282653, 1, 1) para entrenamiento:\n",
    "\n",
    "Aquí, cada muestra tiene 2 pasos de tiempo y 7 características para las variables predictoras, y un solo valor de salida. Esto es adecuado si estás modelando datos donde tienes múltiples pasos de tiempo y varias características.\n",
    "\n",
    "\n",
    "(282653, 14), (282653,) para entrenamiento:\n",
    "\n",
    "En este caso, todas las características se aplanan en una sola dimensión, lo que significa que tratas todas las características como una secuencia única de datos por muestra. Esto puede ser útil en algunos casos donde no necesitas modelar explícitamente múltiples pasos de tiempo, pero simplemente quieres predecir un solo valor en el siguiente paso de tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82bdb21a-f954-4504-a00f-dd45c01e25fe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train_lstm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6f535bd-79c7-4bd3-8e9b-0f2581e23dbb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Construccion del Modelo\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "# Fijar Valores parametros , para asegurar la reproducibilidad de los datos inicializados\n",
    "tf.random.set_seed(123) # Semilla(inicializacion de los parametros o pesos de misma manera)\n",
    "tf.config.experimental.enable_op_determinism() # Cada vez se ejecute de misma manera\n",
    "\n",
    "# El Modelo\n",
    "N_UNITS = 50 # Tamaño del estado oculto de la celda de Memoria de LSTM\n",
    "INPUT_SHAPE = (X_train_lstm.shape[1], X_train_lstm.shape[2]) #pasos atras x n features (feature)\n",
    "\n",
    "modelo = Sequential()\n",
    "modelo.add(LSTM(N_UNITS, input_shape=INPUT_SHAPE))\n",
    "modelo.add(Dense(numero_pasos_futuro, activation='sigmoid')) # linear: problema regresion, sigmoid:clasificacion binaria, softmax:multiclase\n",
    "\n",
    "#RSME: Para problemas de regresion, para tener errores en las mismas unidades de la variable target\n",
    "# def root_mean_squared_error(y_true,y_pred):\n",
    "#     rmse=tf.math.sqtr(tf.math.reduce_mean(tf.square(y_pred-y_true)))\n",
    "#     return rmse\n",
    "\n",
    "# Optimizador para problema de regresion\n",
    "# optimizador = RMSprop(learning_rate=0.05)\n",
    "\n",
    "#Compilation\n",
    "\n",
    "\n",
    "# Compilar el modelo\n",
    "modelo.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy','AUC'])\n",
    "\n",
    "# Entrenamiento del Modelo\n",
    "EPOCHS = 50 # Numero de epocas de entrenamiento\n",
    "BATCH_SIZE = 256 # Numero de lotes que van ingresando al Modelo(Algoritmo)\n",
    "historia = modelo.fit(\n",
    "    x = X_train_lstm,\n",
    "    y = y_train_lstm,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    epochs = EPOCHS,\n",
    "    validation_data = (X_val_lstm, y_val_lstm),\n",
    "    verbose=2  #Imprime en pantalla con va el entrenamiento\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2378c38-4221-4cfd-9726-093a282b9010",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab3e76d2-ed68-4eca-9d66-41d1908e2773",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "5.develoment_modelml",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
